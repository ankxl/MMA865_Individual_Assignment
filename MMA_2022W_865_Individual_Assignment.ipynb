{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "MMA865",
      "language": "python",
      "name": "mma865"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "MMA 2022W 865 Individual Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankxl/MMA865_Individual_Assignment/blob/main/MMA_2022W_865_Individual_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyZCMR6td1Mr"
      },
      "source": [
        "# MMA 2021S 865, Individual Assignment 1\n",
        "\n",
        "Version 2: Updated Janurary 13, 2021.\n",
        "\n",
        "- ANKIT RAI\n",
        "- 20254135\n",
        "- SECTION II\n",
        "- What The Ceo Really Wants From You by R Gopalakrishnan \n",
        "- 15 OCTOBER 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlGJQOaad1Ms"
      },
      "source": [
        "# Question 1 - ELI5\n",
        "\n",
        "_“If you can't explain it simply, you don't understand it well enough.” – Albert Einstein_\n",
        "\n",
        "Explaining technical concepts to a non-technical audience is an underappreciated skill; one which the MMA program aims to give its students; and one that will truly set you apart in the job market. The only way to gain a skill is by practice, so here we go.\n",
        "\n",
        "Answer each question below as though you were talking to a 5 year old (equivalently: a grandma, or a completely non-technical manager, or an Ivey grad). Use your own words. Use analogies where possible. Examples are better than theory. Keep it short, but be complete. Use simple, plain English. Do not use business buzzwords like _actualize, empower, fungible, leverage, or synergize_. Do not use technical buzzwords that most people don’t know like _model, agile, bandwidth, IoT, blockchain, AR, VR, actionable insights_. Inform the audience without going into too much technical detail, and without embarrassing yourself. Your goal is to truly help them understand, not to give what you feel is a “technically precise” answer and move on (but they still don’t understand!). Don’t be that guy!\n",
        "\n",
        "Please keep each answer to 1000 characters or less.\n",
        "\n",
        "Finally, feel free to use [Markdown syntax](https://www.markdownguide.org/basic-syntax/) to format your answer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9lm1L9bd1Mt"
      },
      "source": [
        "### Part 1: What is “Big Data” and how is it different than “regular data”?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvoA1AICd1Mu"
      },
      "source": [
        "\n",
        "1. As the word describes 'Big' data is often referring to the size of the data (Volume). Just imagine we want to record all conversations between a customer and retailer for a year. The conversations would be in hundreds of thousand or millions.\n",
        "2. Big data also is used to describe data which can not be stored in tabular format like text, images, etc. e.g., children story books or interaction that a person may have throughout the day or week or month. Variety in data.\n",
        "3. Data points collect every second or milisecond (almost realtime) also indicate big data (Velocity). e.g., commentary during a hockey or cricket match.\n",
        "4. Veracity: With large amount of data, checking for quality and consistencies is important like commentrator mentions some incorrect fact but might get missed in the volume or speed of incoming data.\n",
        "5. Value: There is no point in collecting big data unless we can derive value from it. Can we analyse the cricket match commentary and player data to devise a framework to get a batsman out (win the match)?\n",
        "\n",
        "- Examples of regular data: household budget or account statement. The budget can be depicted in columns with say date, description, transaction type and amount say 1st of month (date) received salary (description) in account (credited transaction type) and amount. Regular data is often not high volume or collected real time (not high velocity) and can be setup in tabular format like budget.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEKsagXWd1Mu"
      },
      "source": [
        "### Part 2: What is Hadoop? Hint: What problems in previous data storage and processing was Hadoop designed to solve? How did Hadoop accomplish that?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_0Fzj-od1Mu"
      },
      "source": [
        "We are planning a party for large number of guests. Hadoop is like the party planner which allows everyone to help to prepare for the party (open source) and doesnt need specific training from workers (community hardware). \n",
        "The usual problems that host face while planning party are:\n",
        "1. If the number of guest change at last minute, can planners accommodate without huge increase in bill (scale out).\n",
        "2. Things go wrong, like ingredients get spoiled, chef doesnt showup, will the party planner still deliver (fault tolerant).\n",
        "3. Will the planner move the ingredients from different locations to one cook station or setup different cooking stations near ingredient storage or serving location? (Move processing to data). \n",
        "4. While preparing salad does the chef preparing dressing need to worry about vegetable cut? (abstraction). \n",
        "\n",
        "Hadoop\n",
        "- Hadoop supports multiple chefs so the food is cooked simultanesouly (distributed compute). \n",
        "- If the hosts request to accommodate more guests or prepare food faster, Hadoop can add more chefs (scalability). \n",
        "- Hadoop gets more set of smaller pans versus large pans so that they can cook food simultaneously and makes it easier for them to carry and store. Depending upon need Hadoop adds pans (scale out).\n",
        "- Hadoop stores the ingredients at multiple locations so it is easier for chefs to cook in parallel (HDFS). \n",
        "-If for what ever reason the ingredients go bad, Hadoop stores ingredients in other locations and can easily get more (fault tolerant). \n",
        "- Hadoop has a party planning manager (YARN) which is responsible for identifying a lead for each item. e.g., for salad the manager identifies the chef 1 to be responsible for salad prep, chef 1 will ask chef 2 to cut veges, chef 4 to prepare dressing and chef 8 to toss the salad. In case chef 1 is unavailable, party manager will replace him.\n",
        "- If we are serving hot grilled fish for 100 guests, we can’t do it with 1 cook. Hadoop splits this into 10 cook station (map it across multiple compute) and waiters bring the fish from different location to one serving locations (reduce function).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWesjpN8d1Mv"
      },
      "source": [
        "### Part 3: How does Big Data and the cloud help Machine Learning? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAJS3UzNd1Mv"
      },
      "source": [
        "- Lets imaginge we need to move house. We need to book a truck to move goods and if we need to store for a day, we will need to rent a storage for a week. This is a costly investment and inefficient - truck used for an hour but paid for per day.\n",
        "- Let’s imagine cloud like a moving service which allows you to choose the level of support\n",
        ">- Basic (IaaS): where you pay only for amount of time you use the truck and storage unit.\n",
        ">- Advanced (PaaS): where you only get your furniture and dont must worry about loading/ unloading or refueling the truck.\n",
        ">- Complete (SaaS): where provider manages task end to end as desired by you. \n",
        "\n",
        "The key advantages of using Big Data and Cloud in ML are:\n",
        ">- Cost effective: billing is dependent on truck and storage usage per time unit instead of having to rent the truck and storage for day(s). You can also choose your truck depending upon need.\n",
        ">- As the services are cost effective one can start with a small pilot and then scale up if satisfied with performance.\n",
        ">- AI/ ML tools by public cloud providers: moving services company provides differnt services for different user (disabled versus professional movers) but support everyone.\n",
        ">- Ecosystem: lot of other companies offering different add ons like move furtniture through stairs of specific product for rent to move threadmill, etc.\n",
        ">- End to End pipeline: Cloud provides tools not just for building ML solutions but also visualise the output so in our analogy not just move the furniture but unwrap and place it in the right room as desired by user.\n",
        ">- Volume, Variety and Velocity (Big Data): Increase in data can increase the accuracy of machine learning e.g., the more books you read about a topic the more you will understand. Most of real-world data resides in unstructured format like audio or natural text or images and we can take advantage of AI/ML tools by public cloud providers and power of ecosystem to analyse data (described above). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blzNZpsKd1Mw"
      },
      "source": [
        "### Part 4: What is NoSQL?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euQZjTFDd1Mx"
      },
      "source": [
        "NoSQL is also referred as non-relational database. If we can not store data in rows and columns - like bank account statement can be represented in a table- then we need NoSQL e.g.  commentary of a match. There are 4 kinds of NoSQL based on use cases:\n",
        "- Key-value datastore: The easiest example to describe this is dictionary. The dictionary has a key word we are looking up and value is the definition. The keys are indexed alphabetically so its very easy to find the key.\n",
        "- Graph datastore: optimised for network analytics use case. Let say we want to build a family tree and identify the people family knows this datastore would be recommended. \n",
        "- Document datastore: Is a variant of the key value datastore with key difference being in value which is a file format. This is used extensively in applications like storing resume information. The key may be your name and value will be skills, education details, certifications and experience but saved in defined format like XML or JSON.\n",
        "- Columnar: Is very similar to relational database. Let’s take example of bank statement to highlight the advantage of columnar datastore. If user wants to understand all withdrawls from account in the last 1 year, the bank clerk will pull all the data with date of transaction on rows along with amount credited/ debited and transaction type. The computer will have to read through all the rows and columns before sharing result but in columnar data there is one row for date, amount transacted, transaction type and description. The query will only read through rows of interest like transaction amount and type. These speeds up the querying process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgbTZ0exbUk4"
      },
      "source": [
        "### Part 5: Name three ways topic modeling could help a bank."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etDOfiIud1Mx"
      },
      "source": [
        "Topic Modelling is the ability of algorithm/ machine to understand general idea of the message without having the ability to understand the message.\n",
        "\n",
        "1. Organise customer reviews (website, social media, telephonic chat) to identify key themes. The bank may be able to seperate the feedback specific to product or service improvement, bank operations, customer experience, etc. and appropriately act or not to act.\n",
        "2. Customers tend to read about investment products like MF report or equity research report before they invest. Topic modelling based on previous reading patterns can recommend investment products. If a customer is reading research on energy and banking stocks, the model may recommend an MF/ ETF on dividend stocks.\n",
        "3. Data reduction and Information Retrieval: Bank request their customer to call an agent to cancel specific services but sometimes customer to get a better deal (negotiating tactics) call the agent claiming to cancel not intending to cancel. Topic Modelling can mine for specific words or phrases in conversation that will indicate to agent if the customer has a high likelihood to cancel thus should offer discounted services or just negotiating for a better deal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2raqwCjwd1My"
      },
      "source": [
        "### Part 6: What is Apache Spark, exactly, and what are its pros and cons?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4Bc2UBRd1My"
      },
      "source": [
        "Spark is an open-source framework (describe above) that is used for data processing on large datasets leveraging multiple languages. \n",
        "\n",
        "Pros\n",
        "- Support multiple languages like Python, R, Scala, and SQL. e.g., let’s say the system understands French, German, and English; anyone who knows any of the languages can communicate with the system without translation. Spark can distribute python/ R code through user defined functions.\n",
        "- Reduces the number of read and write to/ from memory to reduce the speed of operations. Support all in memory. e.g., like trying to find something in a book without an index and we dont know which book or section of the library the book is in versus finding something in the book in front of you which has an index.\n",
        "- Easier to write applications. Earlier to get compute to execute map-reduce function was multiple lines of complex code whereas with spark it in 2-3 lines of simple code. E.g., we can divide two numbers using the long division route which may take a couple of minutes or just evaluate on a calculator which will be milliseconds.\n",
        "- Support for Big Data. Natural language processing and graph processing capabilities.\n",
        "Cons\n",
        "- requires re-learn python as pyspark. It can be a steep learning curve for new analyst as the code is not exactly same for python and pyspark. E.g., cricket player becoming a baseball player, there will be steep learning curve to understand the rules of the game and develop skill to excel.\n",
        "- Fewer ML algorithm. E.g., imagine a calculator with only + and – operations so if you want to calculate a square root it may be beyond the capability and may want to focus on another way to perform desired operation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uiuc0Wa2d1My"
      },
      "source": [
        "# Question 2: Sentiment Analysis via the ML-based approach\n",
        "\n",
        "Download the “Product Sentiment” dataset from the course portal: sentiment_train.csv and sentiment_test.csv."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv5daIZld1My"
      },
      "source": [
        "### Part 1.a. Loading and Prep\n",
        "\n",
        "Load, clean, and preprocess the data as you find necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjmNEojQd1Mz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8a430c48-f5e3-45f4-ddce-6cd4ed133b62"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# TODO: import other libraries as necessary\n",
        "\n",
        "# Load the training set data\n",
        "df_train = pd.read_csv(\"sentiment_train.csv\")\n",
        "# Analyse the training data: Columns and data type; first 5 rows of data\n",
        "print(df_train.info())\n",
        "print(df_train.head())\n",
        "\n",
        "# Load the testing data\n",
        "df_test = pd.read_csv(\"sentiment_test.csv\")\n",
        "\n",
        "# Analyse the testing data: Columns and data type; first 5 rows of data\n",
        "print(df_test.info())\n",
        "print(df_test.head())\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2400 entries, 0 to 2399\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  2400 non-null   object\n",
            " 1   Polarity  2400 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 37.6+ KB\n",
            "None\n",
            "                                            Sentence  Polarity\n",
            "0                           Wow... Loved this place.         1\n",
            "1                                 Crust is not good.         0\n",
            "2          Not tasty and the texture was just nasty.         0\n",
            "3  Stopped by during the late May bank holiday of...         1\n",
            "4  The selection on the menu was great and so wer...         1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 600 entries, 0 to 599\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  600 non-null    object\n",
            " 1   Polarity  600 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 9.5+ KB\n",
            "None\n",
            "                                            Sentence  Polarity\n",
            "0  A good commentary of today's love and undoubte...         1\n",
            "1  For people who are first timers in film making...         1\n",
            "2  It was very popular when I was in the cinema, ...         1\n",
            "3  It's a feel-good film and that's how I felt wh...         1\n",
            "4  It has northern humour and positive about the ...         1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COPEmCCSd1M0"
      },
      "source": [
        "### Part 1.b. Modeling\n",
        "\n",
        "Use your favorite ML algorithm to train a classification model.  Don’t forget everything that we’ve learned in our ML course: hyperparameter tuning, cross validation, handling imbalanced data, etc. Make reasonable decisions and try to create the best-performing classifier that you can."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNbnyhF_in7K"
      },
      "source": [
        "## Basic Data check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY0wtbVwd1M0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "13ccdad6-8320-48fd-a2c6-aaac6b022b0f"
      },
      "source": [
        "# Check for Missing values in data\n",
        "df_train.isna().sum()\n",
        "# df_test.isna().sum()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence    0\n",
              "Polarity    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qkPQTGFyfk_s",
        "outputId": "71635519-20f2-4f1f-fc6c-1f41621f8ff9"
      },
      "source": [
        "# Check for balance in train dataset\n",
        "df_train[\"Polarity\"].value_counts()\n",
        "# df_test.groupby(\"Polarity\").count()\n",
        "\n",
        "# The weights are almost equal, will leverage class weight of ML algorithm"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1213\n",
              "1    1187\n",
              "Name: Polarity, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "6YVk30CewiMa",
        "outputId": "88a703db-5aa8-481e-df50-7affc4049062"
      },
      "source": [
        "df_train[\"Polarity\"].value_counts().plot.bar()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb6932f3890>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFGCAYAAACls9yvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVnklEQVR4nO3df0xV9/3H8dcF7uUGeplewm2+NJvZ3LeaCELBrQVlGxFW6rKURUEl0DXhj5mg7RIS7Yhp3VwbbWdj68i21E2dLRuR/ShbGiFLdNnSW7ZxF8K1WVibZXHWwb2LlJXf4v3+sfRm1p/fA9f79t7n4y/93Hs975P2k2fOudyLKxaLxQQAAEzKSPYAAADgxgg1AACGEWoAAAwj1AAAGEaoAQAwLCvZA3zUlStXNDk5KbfbLZfLlexxAABIqFgspvn5eeXm5ioj49rrZ3Ohnpyc1MjISLLHAADgjrr//vvl8/muWTcXarfbLek/A3s8niRPg/+vcDisoqKiZI8BpCX2391pbm5OIyMj8f59lLlQf3i72+PxKDs7O8nTwAn+uwHJw/67e93o7V5+mAwAAMMINQAAhhFqAAAMI9QAABhGqAEAMIxQAwBgGKEGAMAwQg0AgGGEGgAAwwg1AACG3VaoR0ZGVFNTo1dffVWSdPHiRT3++ONqbm7W448/rkgkIknq7e3V5s2b1dDQoFOnTkmS5ufn1d7eru3bt6u5uVnnz59P0KkAAJB6bvld31NTU9q/f78qKiria4cPH1ZjY6M2bdqk1157TceOHdPOnTvV2dmpnp4eud1ubdmyRbW1tTpz5ozy8vJ06NAh/f73v9ehQ4d0+PDhhJ6UZZntJ5M9QuJ1vZ3sCRJm4VBLskcAkGZueUXt8Xj0yiuvKBAIxNeeeeYZPfzww5Kk5cuXa3x8XENDQyouLpbP55PX61VZWZlCoZCCwaBqa2slSZWVlQqFQgk6FQAAUs8tQ52VlSWv13vVWk5OjjIzM7WwsKCuri59+ctfVjQald/vjz/H7/crEolctZ6RkSGXy6W5ubklPg0AAFKT419zubCwoN27d+uhhx5SRUWFfvWrX131eCwWu+7rbrT+UeFw2OloQMIMDg4mewTgpvh/NPU4DvU3vvENrVixQjt37pQkBQIBRaPR+ONjY2MqLS1VIBBQJBLR6tWrNT8/r1gsJo/Hc8t/v6ioKDV/r2oKv3+bDsrLy5M9AnBDg4OD/D96F5qdnb3pxamjj2f19vbK7XbriSeeiK+VlJRoeHhYExMTmpycVCgU0rp167R+/XqdPn1aknTmzBk9+OCDTg4JAEBauuUVdTgc1sGDB3XhwgVlZWWpr69P//rXv5Sdna2Wlv/8BOzKlSu1b98+tbe3q7W1VS6XS21tbfL5fNq0aZPefPNNbd++XR6PRwcOHEj4SQEAkCpcsdt90/gO+fAWQKre+k6Lj2elMD6edXdj/929Unnv3ap7fDMZAACGEWoAAAwj1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDCDUAAIYRagAADCPUAAAYRqgBADCMUAMAYBihBgDAMEINAIBhhBoAAMMINQAAhhFqAAAMI9QAABhGqAEAMIxQAwBgGKEGAMAwQg0AgGGEGgAAwwg1AACGEWoAAAwj1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDCDUAAIYRagAADCPUAAAYRqgBADCMUAMAYBihBgDAsNsK9cjIiGpqavTqq69Kki5evKiWlhY1NTXpySef1NzcnCSpt7dXmzdvVkNDg06dOiVJmp+fV3t7u7Zv367m5madP38+QacCAEDquWWop6amtH//flVUVMTXXn75ZTU1Namrq0srVqxQT0+Ppqam1NnZqePHj+vkyZM6ceKExsfH9etf/1p5eXn6yU9+oh07dujQoUMJPSEAAFLJLUPt8Xj0yiuvKBAIxNcGBga0ceNGSVJ1dbWCwaCGhoZUXFwsn88nr9ersrIyhUIhBYNB1dbWSpIqKysVCoUSdCoAAKSeW4Y6KytLXq/3qrXp6Wl5PB5JUn5+viKRiKLRqPx+f/w5fr//mvWMjAy5XK74rXIAAHBzWYv9B2Kx2JKsf1Q4HHY8E5Aog4ODyR4BSEvpvPcchTonJ0czMzPyer0aHR1VIBBQIBBQNBqNP2dsbEylpaUKBAKKRCJavXq15ufnFYvF4lfjN1NUVKTs7Gwn49nW9XayJ8AilJeXJ3sELAb7766Vyntvdnb2phenjj6eVVlZqb6+PklSf3+/qqqqVFJSouHhYU1MTGhyclKhUEjr1q3T+vXrdfr0aUnSmTNn9OCDDzo5JAAAaemWV9ThcFgHDx7UhQsXlJWVpb6+Pn3nO9/RU089pe7ubhUWFqq+vl5ut1vt7e1qbW2Vy+VSW1ubfD6fNm3apDfffFPbt2+Xx+PRgQMH7sR5AQCQElyx233T+A758BZAqt76zmw/mewRsAgLh1qSPQIWgf1390rlvXer7vHNZAAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDCDUAAIYRagAADCPUAAAYRqgBADCMUAMAYBihBgDAMEINAIBhhBoAAMMINQAAhhFqAAAMI9QAABhGqAEAMIxQAwBgGKEGAMAwQg0AgGGEGgAAwwg1AACGEWoAAAwj1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDCDUAAIYRagAADCPUAAAYRqgBADCMUAMAYBihBgDAMEINAIBhhBoAAMOynLxocnJSe/bs0fvvv6/5+Xm1tbWpoKBA+/btkyStWrVK3/zmNyVJR48e1enTp+VyubRz5059/vOfX7LhAQBIdY5C/Ytf/EKf/OQn1d7ertHRUX31q19VQUGBOjo6tHbtWrW3t+u3v/2tPvWpT+mNN97QT3/6U33wwQdqamrShg0blJmZudTnAQBASnJ063v58uUaHx+XJE1MTGjZsmW6cOGC1q5dK0mqrq5WMBjUwMCAqqqq5PF45Pf7dd999+mdd95ZuukBAEhxjkL9pS99Se+9955qa2vV3Nys3bt3Ky8vL/54fn6+IpGIotGo/H5/fN3v9ysSiSx+agAA0oSjW9+vv/66CgsL9cMf/lB/+ctf1NbWJp/PF388Fotd93U3Wr+ecDjsZDQgoQYHB5M9ApCW0nnvOQp1KBTShg0bJEmrV6/W7OysLl++HH98dHRUgUBAgUBAf/vb365Zvx1FRUXKzs52Mp5tXW8newIsQnl5ebJHwGKw/+5aqbz3Zmdnb3px6ujW94oVKzQ0NCRJunDhgnJzc7Vy5Ur96U9/kiT19/erqqpKDz30kM6ePau5uTmNjo5qbGxMn/70p50cEgCAtOToinrr1q3q6OhQc3OzLl++rH379qmgoEBPP/20rly5opKSElVWVkqSGhsb1dzcLJfLpX379ikjg49uAwBwuxyFOjc3Vy+99NI1611dXdestbS0qKWlxclhAABIe1zeAgBgGKEGAMAwQg0AgGGEGgAAwwg1AACGEWoAAAwj1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDCDUAAIYRagAADCPUAAAYRqgBADCMUAMAYBihBgDAMEINAIBhhBoAAMMINQAAhhFqAAAMI9QAABhGqAEAMIxQAwBgGKEGAMAwQg0AgGGEGgAAwwg1AACGEWoAAAwj1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDCDUAAIYRagAADMty+sLe3l4dPXpUWVlZeuKJJ7Rq1Srt3r1bCwsLKigo0AsvvCCPx6Pe3l6dOHFCGRkZamxsVENDw1LODwBASnMU6kuXLqmzs1M/+9nPNDU1pSNHjqivr09NTU165JFH9OKLL6qnp0f19fXq7OxUT0+P3G63tmzZotraWi1btmypzwMAgJTk6NZ3MBhURUWF7rnnHgUCAe3fv18DAwPauHGjJKm6ulrBYFBDQ0MqLi6Wz+eT1+tVWVmZQqHQkp4AAACpzNEV9T/+8Q/NzMxox44dmpiY0K5duzQ9PS2PxyNJys/PVyQSUTQald/vj7/O7/crEokszeQAAKQBx+9Rj4+P67vf/a7ee+89PfbYY4rFYvHH/vvP/+1G69cTDoedjgYkzODgYLJHANJSOu89R6HOz8/XAw88oKysLH3iE59Qbm6uMjMzNTMzI6/Xq9HRUQUCAQUCAUWj0fjrxsbGVFpaelvHKCoqUnZ2tpPxbOt6O9kTYBHKy8uTPQIWg/1310rlvTc7O3vTi1NH71Fv2LBBb731lq5cuaJLly5pampKlZWV6uvrkyT19/erqqpKJSUlGh4e1sTEhCYnJxUKhbRu3TpnZwIAQBpydEV977336uGHH1ZjY6Mkae/evSouLtaePXvU3d2twsJC1dfXy+12q729Xa2trXK5XGpra5PP51vSEwAAIJU5fo9627Zt2rZt21Vrx44du+Z5dXV1qqurc3oYAADSGt9MBgCAYYQaAADDCDUAAIYRagAADCPUAAAYRqgBADCMUAMAYBihBgDAMEINAIBhhBoAAMMINQAAhhFqAAAMI9QAABhGqAEAMIxQAwBgGKEGAMAwQg0AgGGEGgAAwwg1AACGEWoAAAwj1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDCDUAAIYRagAADCPUAAAYRqgBADCMUAMAYBihBgDAMEINAIBhhBoAAMMINQAAhhFqAAAMI9QAABhGqAEAMGxRoZ6ZmVFNTY1+/vOf6+LFi2ppaVFTU5OefPJJzc3NSZJ6e3u1efNmNTQ06NSpU0syNAAA6WJRof7e976nj33sY5Kkl19+WU1NTerq6tKKFSvU09OjqakpdXZ26vjx4zp58qROnDih8fHxJRkcAIB04DjU7777rt555x194QtfkCQNDAxo48aNkqTq6moFg0ENDQ2puLhYPp9PXq9XZWVlCoVCSzI4AADpwHGoDx48qKeeeir+9+npaXk8HklSfn6+IpGIotGo/H5//Dl+v1+RSGQR4wIAkF6ynLzol7/8pUpLS/Xxj3/8uo/HYrH/1/r1hMNhJ6MBCTU4OJjsEYC0lM57z1Goz549q/Pnz+vs2bP65z//KY/Ho5ycHM3MzMjr9Wp0dFSBQECBQEDRaDT+urGxMZWWlt7WMYqKipSdne1kPNu63k72BFiE8vLyZI+AxWD/3bVSee/Nzs7e9OLUUagPHz4c//ORI0d033336c9//rP6+vr06KOPqr+/X1VVVSopKdHevXs1MTGhzMxMhUIhdXR0ODkkAABpyVGor2fXrl3as2ePuru7VVhYqPr6erndbrW3t6u1tVUul0ttbW3y+XxLdUgAAFLeokO9a9eu+J+PHTt2zeN1dXWqq6tb7GEAAEhLfDMZAACGEWoAAAwj1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDCDUAAIYRagAADCPUAAAYRqgBADCMUAMAYBihBgDAMEINAIBhhBoAAMMINQAAhhFqAAAMI9QAABhGqAEAMIxQAwBgGKEGAMAwQg0AgGGEGgAAwwg1AACGEWoAAAwj1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDCDUAAIYRagAADCPUAAAYRqgBADCMUAMAYBihBgDAsCynL3z++ec1ODioy5cv62tf+5qKi4u1e/duLSwsqKCgQC+88II8Ho96e3t14sQJZWRkqLGxUQ0NDUs5PwAAKc1RqN966y399a9/VXd3ty5duqSvfOUrqqioUFNTkx555BG9+OKL6unpUX19vTo7O9XT0yO3260tW7aotrZWy5YtW+rzAAAgJTm69f2Zz3xGL730kiQpLy9P09PTGhgY0MaNGyVJ1dXVCgaDGhoaUnFxsXw+n7xer8rKyhQKhZZuegAAUpyjUGdmZionJ0eS1NPTo8997nOanp6Wx+ORJOXn5ysSiSgajcrv98df5/f7FYlElmBsAADSg+P3qCXpN7/5jXp6evSjH/1IX/ziF+PrsVjsus+/0fr1hMPhxYwGJMTg4GCyRwDSUjrvPceh/t3vfqfvf//7Onr0qHw+n3JycjQzMyOv16vR0VEFAgEFAgFFo9H4a8bGxlRaWnpb/35RUZGys7OdjmdX19vJngCLUF5enuwRsBjsv7tWKu+92dnZm16cOrr1/e9//1vPP/+8fvCDH8R/MKyyslJ9fX2SpP7+flVVVamkpETDw8OamJjQ5OSkQqGQ1q1b5+SQAACkJUdX1G+88YYuXbqkr3/96/G1AwcOaO/everu7lZhYaHq6+vldrvV3t6u1tZWuVwutbW1yefzLdnwAACkOkeh3rp1q7Zu3XrN+rFjx65Zq6urU11dnZPDAACQ9vhmMgAADCPUAAAYRqgBADCMUAMAYBihBgDAMEINAIBhhBoAAMMINQAAhhFqAAAMI9QAABhGqAEAMIxQAwBgGKEGAMAwQg0AgGGEGgAAwwg1AACGEWoAAAwj1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDCDUAAIYRagAADCPUAAAYRqgBADCMUAMAYBihBgDAMEINAIBhhBoAAMMINQAAhhFqAAAMI9QAABhGqAEAMIxQAwBgGKEGAMAwQg0AgGFZd+Igzz33nIaGhuRyudTR0aG1a9feicMCAHDXS3io//CHP+jvf/+7uru79e6776qjo0Pd3d2JPiwAACkh4be+g8GgampqJEkrV67U+++/rw8++CDRhwUAICUk/Io6Go1qzZo18b/7/X5FIhHdc889131+LBaTJM3NzSV6tKT4n1x3skfAIszOziZ7BCwC++/ulcp778Pefdi/j7oj71H/txsN8qH5+XlJ0sjIyJ0Y5457/dH/TfYIWIRwOJzsEbAI7L+7Vzrsvfn5eXm93mvWEx7qQCCgaDQa//vY2JgKCgpu+Pzc3Fzdf//9crvdcrlciR4PAICkisVimp+fV25u7nUfT3io169fryNHjmjbtm06d+6cAoHADW97S1JGRoZ8Pl+ixwIAwIzrXUl/KOGhLisr05o1a7Rt2za5XC4988wziT4kAAApwxW71ZvGAAAgafhmMgAADCPUAAAYRqgBADDsjn+OGqlncnIy/hG8goIC5eTkJHkiIH1NTEwoLy8v2WNgCfHDZHBseHhYzz77rCYmJrR8+XLFYjGNjY3p3nvv1dNPP61Vq1Yle0Qg7Tz22GP68Y9/nOwxsIS4ooZjzz33nJ599lmtXLnyqvVz587pW9/6ll577bUkTQaktpvtrdHR0Ts4Ce4EQg3HYrHYNZGWpDVr1mhhYSEJEwHp4fjx46qoqFAgELjmscuXLydhIiQSoYZjJSUl2rFjh2pqauT3+yX955ew9PX16bOf/WySpwNSV2dnp7797W9r79698ng8Vz02MDCQpKmQKLxHjUX54x//qGAwGP9hskAgoPXr1+uBBx5I8mRAapuenlZ2drYyMq7+8M65c+eu+o2FuPsRagAADONz1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYf8H2yBNxMc6lBUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qd4fYOaoflwu",
        "outputId": "401e328c-a138-474e-ebcc-059689b1fc84"
      },
      "source": [
        "# check for duplicate sentences\n",
        "df_train.duplicated(subset=[\"Sentence\"]).sum()\n",
        "# df_test.duplicated(subset=[\"Sentence\"]).sum()\n",
        "\n",
        "# There are 18 duplicates in the training dataset"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMuv1q81LrPs"
      },
      "source": [
        "# drop the 18 duplicates indentified in previous step\n",
        "df_train = df_train.drop_duplicates(subset=[\"Sentence\"],keep=\"last\")"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YKB5QA2Ofl09",
        "outputId": "86078e79-d83e-4430-c5f3-6e3c9929f696"
      },
      "source": [
        "# Re-Check for balance in train dataset after deleting duplicate sentences\n",
        "df_train[\"Polarity\"].value_counts()\n",
        "\n",
        "# The weights are still almost equal, will leverage class weight of ML algorithm. \n",
        "# 7 instances from class 0 were dropped and 11 instances for class 1 were dropped "
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1206\n",
              "1    1176\n",
              "Name: Polarity, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "zJdcvyKKfl4B",
        "outputId": "05d005e2-74da-441c-fd1c-27f79157e845"
      },
      "source": [
        "df_train.describe().transpose()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Polarity</th>\n",
              "      <td>2382.0</td>\n",
              "      <td>0.493703</td>\n",
              "      <td>0.500065</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count      mean       std  min  25%  50%  75%  max\n",
              "Polarity  2382.0  0.493703  0.500065  0.0  0.0  0.0  1.0  1.0"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5eHc4JTiyq3"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UEXfbx8fl7H"
      },
      "source": [
        "# Import NLTK module and download the necessary collections \n",
        "# (commenting download for output generation)\n",
        "import nltk\n",
        "# nltk.download('all')"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX5y7bbDi5Xb"
      },
      "source": [
        "# New Feature: Total number of sentences for each text in training and test dataset.\n",
        "\n",
        "def Tokenize(x):\n",
        "    return len(nltk.sent_tokenize(x))\n",
        "\n",
        "df_train['Senten_count'] = df_train['Sentence'].apply(lambda x: Tokenize(x))\n",
        "df_test['Senten_count'] = df_test['Sentence'].apply(lambda x: Tokenize(x))\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-55T-1jY0Jwf"
      },
      "source": [
        "# New Feature: Total number of characters for each text in training and test dataset.\n",
        "\n",
        "def length(x):\n",
        "    return len(x)\n",
        "\n",
        "df_train['length'] = df_train['Sentence'].apply(lambda x: length(x))\n",
        "df_test['length'] = df_test['Sentence'].apply(lambda x: length(x))"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVngYg1gtLzV"
      },
      "source": [
        "# New Feature: Total number of words for each text in training and test dataset.\n",
        "\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def counter(x):\n",
        "  r = re.sub('[^a-zA-Z]', ' ', x)\n",
        "  r = r.lower()\n",
        "  r = r.split()\n",
        "  word_count = len(r)\n",
        "  return word_count\n",
        "\n",
        "df_train[\"word_count\"] = df_train['Sentence'].apply(lambda x: counter(x))\n",
        "\n",
        "df_test[\"word_count\"] = df_test['Sentence'].apply(lambda x: counter(x))\n",
        "\n",
        "# New Feature: Total number of unique words for each text in training and test dataset.\n",
        "\n",
        "def UNQ_counter(x):\n",
        "  r = re.sub('[^a-zA-Z]', ' ', x)\n",
        "  r = r.lower()\n",
        "  r = r.split()\n",
        "  word_count = len(r)\n",
        "  unique_word_count = len(set(r))\n",
        "  return word_count\n",
        "\n",
        "df_train[\"UNQ_word_count\"] = df_train['Sentence'].apply(lambda x: UNQ_counter(x))\n",
        "\n",
        "df_test[\"UNQ_word_count\"] = df_test['Sentence'].apply(lambda x: UNQ_counter(x))\n",
        "\n",
        "# New Feature: Build processed text with following features:\n",
        "# 1. replace non alphabet text with spaces\n",
        "# 2. convert text in to lower case\n",
        "# 3. split in to tokens by using default (spaces)\n",
        "# 4. use lemmatizer to lemmatize words\n",
        "# 5. Remove stopwords\n",
        "# 6. re-join the remaining tokens using spaces\n",
        "# 7. Create a new feature called proc_text in training and text dataset \n",
        "\n",
        "\n",
        "def text_processing(x):\n",
        "  r = re.sub('[^a-zA-Z]', ' ', x)\n",
        "  r = r.lower()\n",
        "  r = r.split()\n",
        "  word_count = len(r)\n",
        "  unique_word_count = len(set(r))\n",
        "  r = [lemmatizer.lemmatize(word) for word in r]\n",
        "  r = [word for word in r if word not in stopwords.words('english')]\n",
        "  r = ' '.join(r)\n",
        "  return r\n",
        "\n",
        "df_train[\"proc_text\"] = df_train['Sentence'].apply(lambda x: text_processing(x))\n",
        "\n",
        "df_test[\"proc_text\"] = df_test['Sentence'].apply(lambda x: text_processing(x))\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "CN1nMnJL1tP3",
        "outputId": "91356e7f-4bdc-4a68-c401-35dc5cbddd35"
      },
      "source": [
        "df_train.head(5)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Senten_count</th>\n",
              "      <th>length</th>\n",
              "      <th>word_count</th>\n",
              "      <th>UNQ_word_count</th>\n",
              "      <th>proc_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>wow loved place</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>crust good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>tasty texture wa nasty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>stopped late may bank holiday rick steve recom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>selection menu wa great price</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  ...                                          proc_text\n",
              "0                           Wow... Loved this place.  ...                                    wow loved place\n",
              "1                                 Crust is not good.  ...                                         crust good\n",
              "2          Not tasty and the texture was just nasty.  ...                             tasty texture wa nasty\n",
              "3  Stopped by during the late May bank holiday of...  ...  stopped late may bank holiday rick steve recom...\n",
              "4  The selection on the menu was great and so wer...  ...                      selection menu wa great price\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "TSeWEfSDljRI",
        "outputId": "5c73b416-1efe-43ef-ead7-4078d459e2ac"
      },
      "source": [
        "# Analyse the histogram for length of text (characters in string) for each Polarity class\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.xscale('log')\n",
        "bins = 1.15**(np.arange(0,50))\n",
        "plt.hist(df_train[df_train['Polarity']==0]['length'],bins=bins,alpha=0.8)\n",
        "plt.hist(df_train[df_train['Polarity']==1]['length'],bins=bins,alpha=0.8)\n",
        "plt.legend(('class 0','class 1'))\n",
        "plt.show()\n",
        "\n",
        "# The histogram doesnt yield any distinguishable insights"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "G-Rcgpn3oX6B",
        "outputId": "e2158d92-d2b0-40c3-ebe7-0606d3179578"
      },
      "source": [
        "# Analyse the histogram for word count for each Polarity class\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# plt.xscale('log')\n",
        "bins = 1.2**(np.arange(0,25))\n",
        "plt.hist(df_train[df_train['Polarity']==0]['word_count'],bins=bins,alpha=0.8)\n",
        "plt.hist(df_train[df_train['Polarity']==1]['word_count'],bins=bins,alpha=0.8)\n",
        "plt.legend(('class 0','class 1'))\n",
        "plt.show()\n",
        "\n",
        "# The histogram doesnt yield any distinguishable insights"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "-OPftWAy1cDE",
        "outputId": "b06850b4-39ca-4b9c-e4e6-40288dc0cdb8"
      },
      "source": [
        "# Analyse the histogram for unique word count for each Polarity class\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# plt.xscale('log')\n",
        "bins = 1.2**(np.arange(0,25))\n",
        "plt.hist(df_train[df_train['Polarity']==0]['UNQ_word_count'],bins=bins,alpha=0.8)\n",
        "plt.hist(df_train[df_train['Polarity']==1]['UNQ_word_count'],bins=bins,alpha=0.8)\n",
        "plt.legend(('class 0','class 1'))\n",
        "plt.show()\n",
        "\n",
        "# The histogram doesnt yield any distinguishable insights"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "MokL4eH11cOv",
        "outputId": "626d3957-37c2-40e7-80d7-5a97bc50759e"
      },
      "source": [
        "# Analyse the histogram for number of sentences for each Polarity class\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# plt.xscale('log')\n",
        "bins = 1.2**(np.arange(0,10))\n",
        "plt.hist(df_train[df_train['Polarity']==0]['Senten_count'],bins=bins,alpha=0.5)\n",
        "plt.hist(df_train[df_train['Polarity']==1]['Senten_count'],bins=bins,alpha=0.5)\n",
        "plt.legend(('class 0','class 1'))\n",
        "plt.show()\n",
        "\n",
        "# The histogram doesnt yield any distinguishable insights"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCHhkHKtaoH_"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2nHFLm3Gaou_",
        "outputId": "49e9cfe3-f9c5-4cdf-d968-29e61b3aef60"
      },
      "source": [
        "# Scale the new features as number of sentences range from 1 to 2 while the number of characters range to the 100's\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "df_train[[\"Senten_count\",\"length\",\"word_count\",\"UNQ_word_count\"]] = scaler.fit_transform(df_train[[\"Senten_count\",\"length\",\"word_count\",\"UNQ_word_count\"]])\n",
        "df_train.head()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Senten_count</th>\n",
              "      <th>length</th>\n",
              "      <th>word_count</th>\n",
              "      <th>UNQ_word_count</th>\n",
              "      <th>proc_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "      <td>5.296168</td>\n",
              "      <td>-0.953844</td>\n",
              "      <td>-1.011316</td>\n",
              "      <td>-1.011316</td>\n",
              "      <td>wow loved place</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>-1.111928</td>\n",
              "      <td>-1.011316</td>\n",
              "      <td>-1.011316</td>\n",
              "      <td>crust good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>-0.505940</td>\n",
              "      <td>-0.452588</td>\n",
              "      <td>-0.452588</td>\n",
              "      <td>tasty texture wa nasty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.706034</td>\n",
              "      <td>0.525185</td>\n",
              "      <td>0.525185</td>\n",
              "      <td>stopped late may bank holiday rick steve recom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>-0.031690</td>\n",
              "      <td>0.106140</td>\n",
              "      <td>0.106140</td>\n",
              "      <td>selection menu wa great price</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  ...                                          proc_text\n",
              "0                           Wow... Loved this place.  ...                                    wow loved place\n",
              "1                                 Crust is not good.  ...                                         crust good\n",
              "2          Not tasty and the texture was just nasty.  ...                             tasty texture wa nasty\n",
              "3  Stopped by during the late May bank holiday of...  ...  stopped late may bank holiday rick steve recom...\n",
              "4  The selection on the menu was great and so wer...  ...                      selection menu wa great price\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "RSUXshJCbYm-",
        "outputId": "33c6d6fe-da1e-4ac3-cac6-377153fe0e34"
      },
      "source": [
        "df_test[[\"Senten_count\",\"length\",\"word_count\",\"UNQ_word_count\"]] = scaler.transform(df_test[[\"Senten_count\",\"length\",\"word_count\",\"UNQ_word_count\"]])\n",
        "df_test.head()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Senten_count</th>\n",
              "      <th>length</th>\n",
              "      <th>word_count</th>\n",
              "      <th>UNQ_word_count</th>\n",
              "      <th>proc_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A good commentary of today's love and undoubte...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.310825</td>\n",
              "      <td>0.245822</td>\n",
              "      <td>0.245822</td>\n",
              "      <td>good commentary today love undoubtedly film wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>For people who are first timers in film making...</td>\n",
              "      <td>1</td>\n",
              "      <td>5.296168</td>\n",
              "      <td>0.653339</td>\n",
              "      <td>0.664867</td>\n",
              "      <td>0.664867</td>\n",
              "      <td>people first timer film making think excellent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It was very popular when I was in the cinema, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>1.206632</td>\n",
              "      <td>1.363277</td>\n",
              "      <td>1.363277</td>\n",
              "      <td>wa popular wa cinema good house good reaction ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It's a feel-good film and that's how I felt wh...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.416214</td>\n",
              "      <td>1.083913</td>\n",
              "      <td>1.083913</td>\n",
              "      <td>feel good film felt came cinema</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It has northern humour and positive about the ...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.310825</td>\n",
              "      <td>-0.033542</td>\n",
              "      <td>-0.033542</td>\n",
              "      <td>ha northern humour positive community represents</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  ...                                          proc_text\n",
              "0  A good commentary of today's love and undoubte...  ...  good commentary today love undoubtedly film wo...\n",
              "1  For people who are first timers in film making...  ...  people first timer film making think excellent...\n",
              "2  It was very popular when I was in the cinema, ...  ...  wa popular wa cinema good house good reaction ...\n",
              "3  It's a feel-good film and that's how I felt wh...  ...                    feel good film felt came cinema\n",
              "4  It has northern humour and positive about the ...  ...   ha northern humour positive community represents\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7muH59HoiHG"
      },
      "source": [
        "## Test Train Split for baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eb_AhGvfogzS",
        "outputId": "ab1fdf91-3442-4fbc-d7c0-e8a43765fee4"
      },
      "source": [
        "# split the training set for training and validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y = df_train.Polarity\n",
        "X = df_train.drop(\"Polarity\",axis=1)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, \n",
        "                                                    random_state=666)\n",
        "\n",
        "print('Training Data :', X_train.shape)\n",
        "print('Testing Data : ', X_test.shape)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data : (1786, 6)\n",
            "Testing Data :  (596, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "piKW2oK7ohDG",
        "outputId": "4c770127-faf3-4110-e681-dcd65ae7a3c9"
      },
      "source": [
        "y_train.value_counts().plot.bar()\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb69dcaebd0>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzdFmF2sPYQj"
      },
      "source": [
        "# Dataset for baseline splits\n",
        "X_train_b = X_train[[\"Senten_count\",\"length\",\"word_count\",\"UNQ_word_count\"]]\n",
        "X_test_b = X_test[[\"Senten_count\",\"length\",\"word_count\",\"UNQ_word_count\"]]"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaADA3HpO1wN"
      },
      "source": [
        "## Baseline Model \n",
        "using features like Length, nos of Sentences, nos of words and nos of unique words "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7U7y-C7YO2at",
        "outputId": "74b0a714-36ce-4922-9041-51dddad80df8"
      },
      "source": [
        "# Logistics regression as baseline model with class weights as balanced\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(class_weight=\"balanced\",random_state=666)\n",
        "lr.fit(X_train_b, y_train)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=666, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4QjAOHJPPD0"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Create a prediction set:\n",
        "predictions = lr.predict(X_test_b)\n"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kFmHPvARPPP7",
        "outputId": "dab39ba3-819b-43f6-b735-5bd037d2caf1"
      },
      "source": [
        "# classification report\n",
        "print(metrics.classification_report(y_test,predictions))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.47      0.52       310\n",
            "           1       0.52      0.63      0.57       286\n",
            "\n",
            "    accuracy                           0.55       596\n",
            "   macro avg       0.55      0.55      0.55       596\n",
            "weighted avg       0.55      0.55      0.54       596\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hqSKjZQbP3Q5",
        "outputId": "9f8e28a0-8cb1-4f38-c2ef-7a2a089d967d"
      },
      "source": [
        "from sklearn import metrics\n",
        "# Check AUC\n",
        "print(metrics.roc_auc_score(y_test,lr.predict_proba(X_test_b)[:, 1]))\n",
        "\n",
        "# the model is not good, just better than random guess"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5712271599368374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aUXgORXxSuDR",
        "outputId": "0a8c2a13-fb51-4f95-fc98-9d788e46a159"
      },
      "source": [
        "# Check F1 Score\n",
        "print(metrics.f1_score(y_test,predictions))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5727848101265823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "v7NKxIZCP3Wn",
        "outputId": "f12d9427-5808-4a7d-f8cd-344ddaa11733"
      },
      "source": [
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "cm = ConfusionMatrix(lr, classes=[0,1])\n",
        "cm.fit(X_train_b, y_train)\n",
        "cm.score(X_test_b, y_test)\n",
        "cm.poof();"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyFKGpNz6wcm"
      },
      "source": [
        "## Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQXx8shveHFx"
      },
      "source": [
        "# Create new features: Bag of Words based on processed text (not on original text)\n",
        "y = df_train.Polarity\n",
        "X = df_train.proc_text\n",
        "\n",
        "test = df_test.proc_text"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcKGaxiQohMX"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "cv = CountVectorizer()\n",
        "# tfidf = TfidfVectorizer() \n",
        "# TFIDF model gave a lower auc and f1"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "AVN4WkNaAGIf",
        "outputId": "b348ad73-2318-44e9-e69f-21f8f7a14b4e"
      },
      "source": [
        "X.head(20)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                       wow loved place\n",
              "1                                            crust good\n",
              "2                                tasty texture wa nasty\n",
              "3     stopped late may bank holiday rick steve recom...\n",
              "4                         selection menu wa great price\n",
              "5                           getting angry want damn pho\n",
              "6                                  honeslty taste fresh\n",
              "7     potato like rubber could tell made ahead time ...\n",
              "8                                             fry great\n",
              "9                                           great touch\n",
              "10                                    service wa prompt\n",
              "11                                        would go back\n",
              "12    cashier care ever say still ended wayyy overpr...\n",
              "13         tried cape cod ravoli chicken cranberry mmmm\n",
              "14            wa disgusted wa pretty sure wa human hair\n",
              "15                        wa shocked sign indicate cash\n",
              "16                                   highly recommended\n",
              "17                      waitress wa little slow service\n",
              "18                      place worth time let alone vega\n",
              "19                                                 like\n",
              "Name: proc_text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0-QwEVci5aw"
      },
      "source": [
        "X_bow = cv.fit_transform(X)\n",
        "\n",
        "test_bow = cv.transform(test)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBVxfmBqi5eI"
      },
      "source": [
        "# convert to array\n",
        "X_bow_arr = X_bow.toarray()\n",
        "test_bow_arr = test_bow.toarray()"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMv4xtqOi5k3"
      },
      "source": [
        "# convert to DataFrame\n",
        "X_bow_df = pd.DataFrame(X_bow_arr)\n",
        "\n",
        "test_bow_df = pd.DataFrame(test_bow_arr)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv9X4UL1i5oW"
      },
      "source": [
        "# Add column names\n",
        "X_bow_df.columns = cv.get_feature_names()\n",
        "test_bow_df.columns = cv.get_feature_names()"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "WcOC8MyuArT7",
        "outputId": "c793cfca-01c9-4eb2-cf27-8532fad12934"
      },
      "source": [
        "X_bow_df.head()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abhor</th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>abound</th>\n",
              "      <th>absolute</th>\n",
              "      <th>absolutel</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>absolutley</th>\n",
              "      <th>abstruse</th>\n",
              "      <th>ac</th>\n",
              "      <th>accept</th>\n",
              "      <th>acceptable</th>\n",
              "      <th>access</th>\n",
              "      <th>accessable</th>\n",
              "      <th>accessing</th>\n",
              "      <th>accessory</th>\n",
              "      <th>accessoryone</th>\n",
              "      <th>accident</th>\n",
              "      <th>accidentally</th>\n",
              "      <th>accommodation</th>\n",
              "      <th>accomodate</th>\n",
              "      <th>accompanied</th>\n",
              "      <th>according</th>\n",
              "      <th>accountant</th>\n",
              "      <th>accurately</th>\n",
              "      <th>accused</th>\n",
              "      <th>ache</th>\n",
              "      <th>acknowledged</th>\n",
              "      <th>across</th>\n",
              "      <th>acted</th>\n",
              "      <th>acting</th>\n",
              "      <th>action</th>\n",
              "      <th>activate</th>\n",
              "      <th>activated</th>\n",
              "      <th>activesync</th>\n",
              "      <th>actor</th>\n",
              "      <th>actress</th>\n",
              "      <th>actual</th>\n",
              "      <th>actually</th>\n",
              "      <th>ad</th>\n",
              "      <th>...</th>\n",
              "      <th>worker</th>\n",
              "      <th>working</th>\n",
              "      <th>world</th>\n",
              "      <th>worn</th>\n",
              "      <th>worry</th>\n",
              "      <th>worse</th>\n",
              "      <th>worst</th>\n",
              "      <th>worth</th>\n",
              "      <th>worthless</th>\n",
              "      <th>worthwhile</th>\n",
              "      <th>would</th>\n",
              "      <th>wound</th>\n",
              "      <th>wow</th>\n",
              "      <th>wrap</th>\n",
              "      <th>wrapped</th>\n",
              "      <th>writer</th>\n",
              "      <th>writing</th>\n",
              "      <th>written</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wrongly</th>\n",
              "      <th>ya</th>\n",
              "      <th>yama</th>\n",
              "      <th>yawn</th>\n",
              "      <th>yay</th>\n",
              "      <th>yeah</th>\n",
              "      <th>year</th>\n",
              "      <th>yell</th>\n",
              "      <th>yellow</th>\n",
              "      <th>yellowtail</th>\n",
              "      <th>yelpers</th>\n",
              "      <th>yes</th>\n",
              "      <th>yet</th>\n",
              "      <th>young</th>\n",
              "      <th>youthful</th>\n",
              "      <th>yucky</th>\n",
              "      <th>yukon</th>\n",
              "      <th>yum</th>\n",
              "      <th>yummy</th>\n",
              "      <th>zero</th>\n",
              "      <th>zombiez</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3494 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   abhor  ability  able  abound  absolute  ...  yukon  yum  yummy  zero  zombiez\n",
              "0      0        0     0       0         0  ...      0    0      0     0        0\n",
              "1      0        0     0       0         0  ...      0    0      0     0        0\n",
              "2      0        0     0       0         0  ...      0    0      0     0        0\n",
              "3      0        0     0       0         0  ...      0    0      0     0        0\n",
              "4      0        0     0       0         0  ...      0    0      0     0        0\n",
              "\n",
              "[5 rows x 3494 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rbC8sUsygXf8",
        "outputId": "6cfcfec9-428a-4d27-d40f-9911f81c60d7"
      },
      "source": [
        "X_bow_df.isna().sum().sum()"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ3uT0nCSgIX"
      },
      "source": [
        "## Train Test Split for Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ULpkOc8mSIcP",
        "outputId": "747b9a58-2262-4b6f-b4a4-391bb623c528"
      },
      "source": [
        "# split the training set for training and validation\n",
        "X = X_bow_df\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, \n",
        "                                                    random_state=666)\n",
        "\n",
        "print('Training Data :', X_train.shape)\n",
        "print('Testing Data : ', X_test.shape)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data : (1786, 3494)\n",
            "Testing Data :  (596, 3494)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "BWg89TLwSIgO",
        "outputId": "c5c70974-3b50-41e5-bac0-3a3dbe6ececa"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abhor</th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>abound</th>\n",
              "      <th>absolute</th>\n",
              "      <th>absolutel</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>absolutley</th>\n",
              "      <th>abstruse</th>\n",
              "      <th>ac</th>\n",
              "      <th>accept</th>\n",
              "      <th>acceptable</th>\n",
              "      <th>access</th>\n",
              "      <th>accessable</th>\n",
              "      <th>accessing</th>\n",
              "      <th>accessory</th>\n",
              "      <th>accessoryone</th>\n",
              "      <th>accident</th>\n",
              "      <th>accidentally</th>\n",
              "      <th>accommodation</th>\n",
              "      <th>accomodate</th>\n",
              "      <th>accompanied</th>\n",
              "      <th>according</th>\n",
              "      <th>accountant</th>\n",
              "      <th>accurately</th>\n",
              "      <th>accused</th>\n",
              "      <th>ache</th>\n",
              "      <th>acknowledged</th>\n",
              "      <th>across</th>\n",
              "      <th>acted</th>\n",
              "      <th>acting</th>\n",
              "      <th>action</th>\n",
              "      <th>activate</th>\n",
              "      <th>activated</th>\n",
              "      <th>activesync</th>\n",
              "      <th>actor</th>\n",
              "      <th>actress</th>\n",
              "      <th>actual</th>\n",
              "      <th>actually</th>\n",
              "      <th>ad</th>\n",
              "      <th>...</th>\n",
              "      <th>worker</th>\n",
              "      <th>working</th>\n",
              "      <th>world</th>\n",
              "      <th>worn</th>\n",
              "      <th>worry</th>\n",
              "      <th>worse</th>\n",
              "      <th>worst</th>\n",
              "      <th>worth</th>\n",
              "      <th>worthless</th>\n",
              "      <th>worthwhile</th>\n",
              "      <th>would</th>\n",
              "      <th>wound</th>\n",
              "      <th>wow</th>\n",
              "      <th>wrap</th>\n",
              "      <th>wrapped</th>\n",
              "      <th>writer</th>\n",
              "      <th>writing</th>\n",
              "      <th>written</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wrongly</th>\n",
              "      <th>ya</th>\n",
              "      <th>yama</th>\n",
              "      <th>yawn</th>\n",
              "      <th>yay</th>\n",
              "      <th>yeah</th>\n",
              "      <th>year</th>\n",
              "      <th>yell</th>\n",
              "      <th>yellow</th>\n",
              "      <th>yellowtail</th>\n",
              "      <th>yelpers</th>\n",
              "      <th>yes</th>\n",
              "      <th>yet</th>\n",
              "      <th>young</th>\n",
              "      <th>youthful</th>\n",
              "      <th>yucky</th>\n",
              "      <th>yukon</th>\n",
              "      <th>yum</th>\n",
              "      <th>yummy</th>\n",
              "      <th>zero</th>\n",
              "      <th>zombiez</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1672</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>980</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1846</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3494 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      abhor  ability  able  abound  absolute  ...  yukon  yum  yummy  zero  zombiez\n",
              "971       0        0     0       0         0  ...      0    0      0     0        0\n",
              "1672      0        0     0       0         0  ...      0    0      0     0        0\n",
              "520       0        0     0       0         0  ...      0    0      0     0        0\n",
              "980       0        0     0       0         0  ...      0    0      0     0        0\n",
              "1846      0        0     0       0         0  ...      0    0      0     0        0\n",
              "\n",
              "[5 rows x 3494 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lknzAnzDfe5X"
      },
      "source": [
        "## Logitics Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ROS-O5NVSIjq",
        "outputId": "38f08fbc-27cb-4e03-cf5d-d592854de195"
      },
      "source": [
        "# Logistics regression as baseline model with class weights as balanced\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(class_weight=\"balanced\",random_state=666)\n",
        "lr.fit(X_train, y_train)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=666, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3dfCxb-SInE"
      },
      "source": [
        "# Create a prediction set:\n",
        "predictions = lr.predict(X_test)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rxzw8nOVSIqV",
        "outputId": "73cfe666-dd3d-49fb-b490-e0269d87e06c"
      },
      "source": [
        "# classification report\n",
        "print(metrics.classification_report(y_test,predictions))\n",
        "# Accuracy is 77%"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       310\n",
            "           1       0.79      0.72      0.75       286\n",
            "\n",
            "    accuracy                           0.77       596\n",
            "   macro avg       0.77      0.77      0.77       596\n",
            "weighted avg       0.77      0.77      0.77       596\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "B_pHzhUffx5E",
        "outputId": "3f994300-dd2a-4eb8-f385-ca51e8d8b5b0"
      },
      "source": [
        "from sklearn import metrics\n",
        "# Check AUC\n",
        "print(metrics.roc_auc_score(y_test,lr.predict_proba(X_test)[:, 1]))\n",
        "\n",
        "# AUC 0.8425 is big improvement over the baseline model. "
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8424881570042859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SZe1I7TzfyFk",
        "outputId": "40848e4d-5524-47c6-8a86-3c76b3bab01c"
      },
      "source": [
        "# Check F1 Score\n",
        "print(metrics.f1_score(y_test,predictions))\n",
        "\n",
        "# F1 0.7541 is big improvement over the baseline model. "
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7540983606557377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "J0HJxrD3fyP2",
        "outputId": "f54f0904-5c0b-4e5c-a105-51defe6d6752"
      },
      "source": [
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "cm = ConfusionMatrix(lr, classes=[0,1])\n",
        "cm.fit(X_train, y_train)\n",
        "cm.score(X_test, y_test)\n",
        "cm.poof();"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzNpNc4JNw77"
      },
      "source": [
        "## Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "c0A-2Di3fyhd",
        "outputId": "0addfa4b-6c91-4aaa-905c-fe08211d4b07"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "lr = LogisticRegression(class_weight=\"balanced\",random_state=666)\n",
        "\n",
        "scores = cross_validate(lr, X_train, y_train, cv=5, scoring=['f1','f1_weighted',\n",
        "                                                             'roc_auc','accuracy'])\n",
        "\n",
        "sorted(scores.keys())\n",
        "\n",
        "#print the mean for 5 fold cross validation\n",
        "print(\"the f1 mean for 5 fold cross validation is {}\".format(\n",
        "    scores[\"test_f1\"].mean()))\n",
        "print(\"the f1_weighted mean for 5 fold cross validation is {}\".format(\n",
        "    scores[\"test_f1_weighted\"].mean()))\n",
        "print(\"the ROC AUC mean for 5 fold cross validation is {}\".format(\n",
        "    scores[\"test_roc_auc\"].mean()))\n",
        "print(\"the Accuracy mean for 5 fold cross validation is {}\".format(\n",
        "    scores[\"test_accuracy\"].mean()))"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the f1 mean for 5 fold cross validation is 0.7890302338882266\n",
            "the f1_weighted mean for 5 fold cross validation is 0.7979971665712041\n",
            "the ROC AUC mean for 5 fold cross validation is 0.8671912030353119\n",
            "the Accuracy mean for 5 fold cross validation is 0.7984273038824468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flUnQGDTN8Cy"
      },
      "source": [
        "## Hyper parameter Tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4sVecaXX6Ks"
      },
      "source": [
        "# Grid Search hyper-parameter tuning\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "lr = LogisticRegression(random_state=666)\n",
        "\n",
        "\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l2']\n",
        "class_weight = ['balanced',None] \n",
        "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "max_iter = [1000,500]\n",
        "\n",
        "grid = dict(solver=solvers,penalty=penalty,C=c_values,max_iter=max_iter,\n",
        "            class_weight=class_weight)\n",
        "\n",
        "# param_grid = dict(penalty=penalty,\n",
        "#                   c=C,\n",
        "#                   class_weight=class_weight,\n",
        "#                   solver=solver,\n",
        "#                   max_iter = max_iter)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WLpnSg6uYLYM",
        "outputId": "99da9179-81ae-4aef-dcaf-21219132a747"
      },
      "source": [
        "search = GridSearchCV(lr, param_grid=grid, n_jobs=-1, cv=5, scoring='f1_weighted',\n",
        "                      error_score=0, verbose=1)\n",
        "search = search.fit(X_train, y_train)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   37.4s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.1min finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMYTc14uZAU_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fef44a47-4ad0-40e5-fda6-6a27eb15870d"
      },
      "source": [
        "print('Best Score: ', search.best_score_)\n",
        "print('Best Params: ', search.best_params_)\n",
        "\n",
        "# the F1 score increased from 0.7977 to 0.7986"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score:  0.7985772483936093\n",
            "Best Params:  {'C': 1.0, 'class_weight': 'balanced', 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_bucqS4OOk9n",
        "outputId": "8bd96a99-1014-4ec5-ad60-3c3b10da411b"
      },
      "source": [
        "search = GridSearchCV(lr, param_grid=grid, n_jobs=-1, cv=5, scoring='accuracy',\n",
        "                      error_score=0, verbose=1)\n",
        "search = search.fit(X_train, y_train)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   37.3s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.1min finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewX4DQm4OlRl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d2fb783a-1598-4925-8886-1e4f70c32276"
      },
      "source": [
        "print('Best Score: ', search.best_score_)\n",
        "print('Best Params: ', search.best_params_)\n",
        "\n",
        "# the accuracy and F1 score hyperparameter tunning best score configurations are the same.\n",
        "# the accuracy increased from 0.7985 to 0.7990"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score:  0.7989875279720826\n",
            "Best Params:  {'C': 1.0, 'class_weight': 'balanced', 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS49UoJZrxfu"
      },
      "source": [
        "## Re-Train the model on whole dataset with Tuned Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdgZvl_oZArA"
      },
      "source": [
        "lr = LogisticRegression(random_state=666,C = 1.0, class_weight= 'balanced', \n",
        "                        max_iter = 1000, penalty= 'l2', solver= 'liblinear')\n",
        "\n",
        "lr = lr.fit(X_train, y_train)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vCXftB2soHb"
      },
      "source": [
        "# Create a prediction set:\n",
        "predictions = lr.predict(test_bow_df)\n",
        "prob = lr.predict_proba(test_bow_df)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwrHehcMs9w7"
      },
      "source": [
        "y_df_test = df_test.Polarity"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGzcS1T-Vd2_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "c4d5491b-2fd1-42ec-9138-297b42b4e2b2"
      },
      "source": [
        "print(lr.coef_, lr.intercept_)\n",
        "coef = pd.DataFrame(lr.coef_,columns=X_train.columns)\n",
        "\n",
        "coef = pd.concat([pd.DataFrame(lr.intercept_),coef],axis=1)\n",
        "coef.head()\n",
        "\n",
        "#0 is the intercept"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.29825616 -0.10562497  0.24210394 ...  0.39622274 -0.84964676 -0.17790113]] [-0.36329847]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>abhor</th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>abound</th>\n",
              "      <th>absolute</th>\n",
              "      <th>absolutel</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>absolutley</th>\n",
              "      <th>abstruse</th>\n",
              "      <th>ac</th>\n",
              "      <th>accept</th>\n",
              "      <th>acceptable</th>\n",
              "      <th>access</th>\n",
              "      <th>accessable</th>\n",
              "      <th>accessing</th>\n",
              "      <th>accessory</th>\n",
              "      <th>accessoryone</th>\n",
              "      <th>accident</th>\n",
              "      <th>accidentally</th>\n",
              "      <th>accommodation</th>\n",
              "      <th>accomodate</th>\n",
              "      <th>accompanied</th>\n",
              "      <th>according</th>\n",
              "      <th>accountant</th>\n",
              "      <th>accurately</th>\n",
              "      <th>accused</th>\n",
              "      <th>ache</th>\n",
              "      <th>acknowledged</th>\n",
              "      <th>across</th>\n",
              "      <th>acted</th>\n",
              "      <th>acting</th>\n",
              "      <th>action</th>\n",
              "      <th>activate</th>\n",
              "      <th>activated</th>\n",
              "      <th>activesync</th>\n",
              "      <th>actor</th>\n",
              "      <th>actress</th>\n",
              "      <th>actual</th>\n",
              "      <th>actually</th>\n",
              "      <th>...</th>\n",
              "      <th>worker</th>\n",
              "      <th>working</th>\n",
              "      <th>world</th>\n",
              "      <th>worn</th>\n",
              "      <th>worry</th>\n",
              "      <th>worse</th>\n",
              "      <th>worst</th>\n",
              "      <th>worth</th>\n",
              "      <th>worthless</th>\n",
              "      <th>worthwhile</th>\n",
              "      <th>would</th>\n",
              "      <th>wound</th>\n",
              "      <th>wow</th>\n",
              "      <th>wrap</th>\n",
              "      <th>wrapped</th>\n",
              "      <th>writer</th>\n",
              "      <th>writing</th>\n",
              "      <th>written</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wrongly</th>\n",
              "      <th>ya</th>\n",
              "      <th>yama</th>\n",
              "      <th>yawn</th>\n",
              "      <th>yay</th>\n",
              "      <th>yeah</th>\n",
              "      <th>year</th>\n",
              "      <th>yell</th>\n",
              "      <th>yellow</th>\n",
              "      <th>yellowtail</th>\n",
              "      <th>yelpers</th>\n",
              "      <th>yes</th>\n",
              "      <th>yet</th>\n",
              "      <th>young</th>\n",
              "      <th>youthful</th>\n",
              "      <th>yucky</th>\n",
              "      <th>yukon</th>\n",
              "      <th>yum</th>\n",
              "      <th>yummy</th>\n",
              "      <th>zero</th>\n",
              "      <th>zombiez</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.363298</td>\n",
              "      <td>-0.298256</td>\n",
              "      <td>-0.105625</td>\n",
              "      <td>0.242104</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.233648</td>\n",
              "      <td>-0.205755</td>\n",
              "      <td>0.308258</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.165781</td>\n",
              "      <td>0.27357</td>\n",
              "      <td>-0.293514</td>\n",
              "      <td>-0.172575</td>\n",
              "      <td>-0.278849</td>\n",
              "      <td>0.261477</td>\n",
              "      <td>0.304098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.41558</td>\n",
              "      <td>-0.26997</td>\n",
              "      <td>0.016221</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.345976</td>\n",
              "      <td>0.105749</td>\n",
              "      <td>-0.270689</td>\n",
              "      <td>-0.008087</td>\n",
              "      <td>-0.036305</td>\n",
              "      <td>-0.096925</td>\n",
              "      <td>-0.008567</td>\n",
              "      <td>0.208313</td>\n",
              "      <td>0.351082</td>\n",
              "      <td>-0.032157</td>\n",
              "      <td>-0.110237</td>\n",
              "      <td>-0.134985</td>\n",
              "      <td>-0.147775</td>\n",
              "      <td>0.102781</td>\n",
              "      <td>0.140847</td>\n",
              "      <td>0.125906</td>\n",
              "      <td>-0.031503</td>\n",
              "      <td>0.797482</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.06467</td>\n",
              "      <td>0.044043</td>\n",
              "      <td>0.287987</td>\n",
              "      <td>0.09883</td>\n",
              "      <td>-0.408983</td>\n",
              "      <td>-0.197018</td>\n",
              "      <td>-1.848626</td>\n",
              "      <td>-0.061895</td>\n",
              "      <td>-0.453315</td>\n",
              "      <td>0.251499</td>\n",
              "      <td>-0.12188</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.481263</td>\n",
              "      <td>-0.056886</td>\n",
              "      <td>0.106391</td>\n",
              "      <td>0.125906</td>\n",
              "      <td>-0.140717</td>\n",
              "      <td>0.144417</td>\n",
              "      <td>-0.03413</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.211529</td>\n",
              "      <td>-0.329395</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.193282</td>\n",
              "      <td>-0.14207</td>\n",
              "      <td>0.1986</td>\n",
              "      <td>-0.278343</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.190068</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.207991</td>\n",
              "      <td>0.093534</td>\n",
              "      <td>-0.089876</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.329181</td>\n",
              "      <td>0.396223</td>\n",
              "      <td>-0.849647</td>\n",
              "      <td>-0.177901</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 3495 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0     abhor   ability  ...     yummy      zero   zombiez\n",
              "0 -0.363298 -0.298256 -0.105625  ...  0.396223 -0.849647 -0.177901\n",
              "\n",
              "[1 rows x 3495 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHrdNytFd1M0"
      },
      "source": [
        "### Part 1.c. Assessing\n",
        "\n",
        "Use the testing data to measure the accuracy and F1-score of your model.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiS4GXCSs94m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e1abdbd2-4dab-4962-cc5b-27848adfbf66"
      },
      "source": [
        "# classification report\n",
        "print(metrics.classification_report(y_df_test,predictions))\n",
        "\n",
        "# Accuracy is 75% which is lower than hyper parameter tunning. F1 score is 0.7353 \n",
        "# is lower than hyperparameter tunning model. There is a possibility of over \n",
        "# fitting or sometype of drift."
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.85      0.77       287\n",
            "           1       0.83      0.66      0.74       313\n",
            "\n",
            "    accuracy                           0.75       600\n",
            "   macro avg       0.76      0.76      0.75       600\n",
            "weighted avg       0.77      0.75      0.75       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dagJC29stOEK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c7dabe97-5e6e-4401-b80b-909d06f92618"
      },
      "source": [
        "from sklearn import metrics\n",
        "# Check AUC\n",
        "print(metrics.roc_auc_score(y_df_test,lr.predict_proba(test_bow_df)[:, 1]))"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8443076443543989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-n37Kzfs-AP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4828bb8e-9e35-4dab-d7f3-5a3b0397971e"
      },
      "source": [
        "# Check F1 Score\n",
        "print(metrics.f1_score(y_df_test,predictions))"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7353463587921847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFQgYh9rtgg4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "ff0e8df6-d4c0-4ca2-96aa-5a4bb3d7d83f"
      },
      "source": [
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "cm = ConfusionMatrix(lr, classes=[0,1])\n",
        "cm.fit(X_train, y_train)\n",
        "cm.score(test_bow_df, y_df_test)\n",
        "cm.poof();"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40hmco7wd1M1"
      },
      "source": [
        "### Part 2. Given the accuracy and F1-score of your model, are you satisfied with the results, from a business point of view? Explain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yaa02kpMijO6"
      },
      "source": [
        "# NLTK Sentiment Analyser\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sent = SentimentIntensityAnalyzer()\n",
        "\n",
        "def check_sentiment(x):\n",
        "    if sent.polarity_scores(x)['compound']>0:\n",
        "      result = 1\n",
        "    else:\n",
        "      result=0\n",
        "    return result\n",
        "\n"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TEhhoWhtG5N"
      },
      "source": [
        "# Textblob Sentiment Analyser\n",
        "from textblob import TextBlob\n",
        "import textwrap\n",
        "\n",
        "def check_sentiment_tb(x):\n",
        "    if TextBlob(x).polarity > 0:\n",
        "      result = 1\n",
        "    else:\n",
        "      result=0\n",
        "    return result\n",
        "\n",
        "np.set_printoptions(linewidth=160)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI04Lr5a9-O_"
      },
      "source": [
        "# Check pre-trained models on training data and measure metric performance\n",
        "df_train[\"NLTK_Pol\"]=df_train[\"Sentence\"].apply(lambda x: check_sentiment(x))\n",
        "df_train[\"TB_Pol\"]=df_train[\"Sentence\"].apply(lambda x: check_sentiment_tb(x))"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjvytSVB9-Tu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "41c282f3-79e0-4026-e6c9-8219f44b7508"
      },
      "source": [
        " # classification report\n",
        "print(metrics.classification_report(df_train[\"Polarity\"],df_train[\"NLTK_Pol\"]))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.82      0.82      1206\n",
            "           1       0.81      0.80      0.81      1176\n",
            "\n",
            "    accuracy                           0.81      2382\n",
            "   macro avg       0.81      0.81      0.81      2382\n",
            "weighted avg       0.81      0.81      0.81      2382\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yglZlsW_9-Xj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "07b52c5b-b181-4de7-e9d3-288ab1590b3f"
      },
      "source": [
        "# classification report\n",
        "print(metrics.classification_report(df_train[\"Polarity\"],df_train[\"TB_Pol\"]))"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.76      0.78      1206\n",
            "           1       0.76      0.81      0.78      1176\n",
            "\n",
            "    accuracy                           0.78      2382\n",
            "   macro avg       0.78      0.78      0.78      2382\n",
            "weighted avg       0.78      0.78      0.78      2382\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vu_JuOiU9-mL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ee95d293-d496-45ee-d612-77bd920f7fb9"
      },
      "source": [
        "# Check F1 Score\n",
        "print(metrics.f1_score(df_train[\"Polarity\"],df_train[\"NLTK_Pol\"]))"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8083832335329341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYqKFErl-D4Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b44758ef-53a9-4332-b672-8c70e30ac14e"
      },
      "source": [
        "# Check F1 Score \n",
        "print(metrics.f1_score(df_train[\"Polarity\"],df_train[\"TB_Pol\"]))"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7836160529582127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNWYARF88Vre"
      },
      "source": [
        "# Check pre-trained models on test data and measure metric performance\n",
        "# Entire text \n",
        "df_test[\"NLTK_Pol\"]=df_test[\"Sentence\"].apply(lambda x: check_sentiment(x))\n",
        "df_test[\"TB_Pol\"]=df_test[\"Sentence\"].apply(lambda x: check_sentiment_tb(x))"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVLPFoZZA7aT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0f872d09-e0c4-4a0c-c208-2e0b132581b4"
      },
      "source": [
        "# classification report\n",
        "print(metrics.confusion_matrix(y_df_test,df_test[\"NLTK_Pol\"]))"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[237  50]\n",
            " [ 68 245]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlABCoD0A7QS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a0011fad-2707-4173-c281-1c34c7c9b872"
      },
      "source": [
        "# classification report\n",
        "print(metrics.confusion_matrix(y_df_test,df_test[\"TB_Pol\"]))"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[220  67]\n",
            " [ 75 238]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ0olwxa8ZQs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b0ec1ef0-78a2-471b-a229-3417b830a344"
      },
      "source": [
        "# classification report\n",
        "print(metrics.classification_report(y_df_test,df_test[\"NLTK_Pol\"]))"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.83      0.80       287\n",
            "           1       0.83      0.78      0.81       313\n",
            "\n",
            "    accuracy                           0.80       600\n",
            "   macro avg       0.80      0.80      0.80       600\n",
            "weighted avg       0.80      0.80      0.80       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKCRwjyU8ZVx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "27164646-5337-46bd-8124-21a1f6e4db6f"
      },
      "source": [
        "# classification report\n",
        "print(metrics.classification_report(y_df_test,df_test[\"TB_Pol\"]))"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.77      0.76       287\n",
            "           1       0.78      0.76      0.77       313\n",
            "\n",
            "    accuracy                           0.76       600\n",
            "   macro avg       0.76      0.76      0.76       600\n",
            "weighted avg       0.76      0.76      0.76       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S0s5iog8ZZg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "61df2e0b-4d1e-4d6e-c888-d3682cacfeaa"
      },
      "source": [
        "# Check F1 Score\n",
        "print(metrics.f1_score(y_df_test,df_test[\"NLTK_Pol\"]))"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.805921052631579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f21iBw38ZdI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "87fb19e3-94e0-42e4-b614-e6952b068c0c"
      },
      "source": [
        "# Check F1 Score \n",
        "print(metrics.f1_score(y_df_test,df_test[\"TB_Pol\"]))"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7702265372168284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jIbgveM0LzK"
      },
      "source": [
        "# Check pre-trained models on test data and measure metric performance\n",
        "# Entire tex\n",
        "df_test[\"NLTK_Pol\"]=df_test[\"proc_text\"].apply(lambda x: check_sentiment(x))\n",
        "df_test[\"TB_Pol\"]=df_test[\"proc_text\"].apply(lambda x: check_sentiment_tb(x))"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJh70fVeBHsv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "57b52821-f597-4939-9e92-112588cebf72"
      },
      "source": [
        "# classification report\n",
        "print(metrics.confusion_matrix(y_df_test,df_test[\"NLTK_Pol\"]))"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[225  62]\n",
            " [ 70 243]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RrfjUM2BIG7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "feb52ea7-5a0f-4536-e7c9-aa7617c1e21a"
      },
      "source": [
        "# classification report\n",
        "print(metrics.confusion_matrix(y_df_test,df_test[\"TB_Pol\"]))"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[219  68]\n",
            " [ 81 232]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSN39SEv1xEZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7647c34e-9577-450d-bbc8-c2c3b560f52f"
      },
      "source": [
        "# classification report\n",
        "print(metrics.classification_report(y_df_test,df_test[\"NLTK_Pol\"]))"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.78      0.77       287\n",
            "           1       0.80      0.78      0.79       313\n",
            "\n",
            "    accuracy                           0.78       600\n",
            "   macro avg       0.78      0.78      0.78       600\n",
            "weighted avg       0.78      0.78      0.78       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOHtfQOE1xlA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "93cacc4b-db64-4848-9a9c-a0ae2dadf398"
      },
      "source": [
        "# classification report\n",
        "print(metrics.classification_report(y_df_test,df_test[\"TB_Pol\"]))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.76      0.75       287\n",
            "           1       0.77      0.74      0.76       313\n",
            "\n",
            "    accuracy                           0.75       600\n",
            "   macro avg       0.75      0.75      0.75       600\n",
            "weighted avg       0.75      0.75      0.75       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PemZ9Kb62TqH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ff176347-7375-41eb-80e1-d27f8a6d76f9"
      },
      "source": [
        "# Check F1 Score\n",
        "print(metrics.f1_score(y_df_test,df_test[\"NLTK_Pol\"]))"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7864077669902914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aJDcpCH2Us-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a9061017-5125-488a-b35e-1e56b39f932b"
      },
      "source": [
        "# Check F1 Score \n",
        "print(metrics.f1_score(y_df_test,df_test[\"TB_Pol\"]))"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7569331158238173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izVASTQ6d1M1"
      },
      "source": [
        "The best way to evaluate a model is to define a customised payoff/ cost matrix and helps to understand how to value false positive and false negatives. \n",
        "\n",
        "- The accuracy of Logistic Regression model (df_test) is 0.75\n",
        "- The AUC of Logistic Regression model (df_test) is 0.844\n",
        "- The f1 score of Logistic Regression model (df_test) is 0.735\n",
        "\n",
        "\n",
        "- The accuracy of NLTK Sentiment Analysis model (df_test) is 0.78 increases to 0.80 with entire text versus processed text (very close to training set metrics)\n",
        "- The f1 score of NLTK Sentiment Analysis model (df_test) is 0.786 increases to 0.806 with entire text versus processed text (very close to training set metrics)\n",
        "\n",
        "\n",
        "- The accuracy of Textblob Sentiment Analysis model (df_test) is 0.75 increases to 0.76 with entire text versus processed text. (close to training set metrics)\n",
        "- The f1 score of Textblob Sentiment Analysis model (df_test) is 0.757 increases to 0.770 with entire text versus processed text.(close to training set metrics)\n",
        "\n",
        "Ideally unless I believe that my input data is significantly different from training data or pre-trained model training data i.e. specific to my industry or organisation I would rather use pre-trained models. The accuracy and f1 scores are slightly better and I can work off the shelf to deploy the solution faster wihtout really increasing the compute or storage needs. The pre-trained model does reduce the False Negatives from 106 (LR model) to 68 with NLTK and 75 with TextBlob.\n",
        "\n",
        "\n",
        "In the absense of cost payoff matrix I will assume the cost of False negatives are very high as we are trying to convert the detractors to promoters which require time, resource and moentary investment.\n",
        "\n",
        "Lets assume that we can not use the pre-trained models for building this analysis. I think my model has good accuracy (75%), great AUC score of 0.844, great precision for class positive (1) of 0.83 though we can improve the recall by balancing the trade off between recall and precision by adjusting the thresholds. As the custom metric is heavily focused on precision for class 0 before deployment I would like to optimize the model based on the custom metric.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HVFjHlfd1M1"
      },
      "source": [
        "### Part 3. Show five example instances in which your model’s predictions were incorrect. Describe why you think the model was wrong. Don’t just guess: dig deep to figure out the root cause."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IAUXUQt1AAH"
      },
      "source": [
        "def check_sentiment(x):\n",
        "    return sent.polarity_scores(x)['compound']"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN737Ypg1Av8"
      },
      "source": [
        "def check_sentiment_tb(x):\n",
        "    return TextBlob(x).polarity"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad7SWEHwd1M2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "81952170-af6f-4404-9687-73197b6e90bd"
      },
      "source": [
        "# Concaternate the test dataset with predictions and probabilities\n",
        "data = pd.concat([df_test,pd.DataFrame(predictions),pd.DataFrame(prob)],axis=1)\n",
        "data.head()"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Senten_count</th>\n",
              "      <th>length</th>\n",
              "      <th>word_count</th>\n",
              "      <th>UNQ_word_count</th>\n",
              "      <th>proc_text</th>\n",
              "      <th>NLTK_Pol</th>\n",
              "      <th>TB_Pol</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A good commentary of today's love and undoubte...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.310825</td>\n",
              "      <td>0.245822</td>\n",
              "      <td>0.245822</td>\n",
              "      <td>good commentary today love undoubtedly film wo...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.014585</td>\n",
              "      <td>0.985415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>For people who are first timers in film making...</td>\n",
              "      <td>1</td>\n",
              "      <td>5.296168</td>\n",
              "      <td>0.653339</td>\n",
              "      <td>0.664867</td>\n",
              "      <td>0.664867</td>\n",
              "      <td>people first timer film making think excellent...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.123060</td>\n",
              "      <td>0.876940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It was very popular when I was in the cinema, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>1.206632</td>\n",
              "      <td>1.363277</td>\n",
              "      <td>1.363277</td>\n",
              "      <td>wa popular wa cinema good house good reaction ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.020820</td>\n",
              "      <td>0.979180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It's a feel-good film and that's how I felt wh...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.416214</td>\n",
              "      <td>1.083913</td>\n",
              "      <td>1.083913</td>\n",
              "      <td>feel good film felt came cinema</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.097856</td>\n",
              "      <td>0.902144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It has northern humour and positive about the ...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.310825</td>\n",
              "      <td>-0.033542</td>\n",
              "      <td>-0.033542</td>\n",
              "      <td>ha northern humour positive community represents</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.488987</td>\n",
              "      <td>0.511013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  ...         1\n",
              "0  A good commentary of today's love and undoubte...  ...  0.985415\n",
              "1  For people who are first timers in film making...  ...  0.876940\n",
              "2  It was very popular when I was in the cinema, ...  ...  0.979180\n",
              "3  It's a feel-good film and that's how I felt wh...  ...  0.902144\n",
              "4  It has northern humour and positive about the ...  ...  0.511013\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkISHSiH6aUY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "eb4344d8-4a2c-4c3b-8cce-82fdb3ee6c49"
      },
      "source": [
        "# rename the columns\n",
        "data.columns = ['Sentence','Polarity','Senten_count','length','word_count','UNQ_word_count','proc_text',\"NLTK_Pol\",\"TB_Pol\",\"Prediction\",\"Prob_Class_0\",\"Prob_Class_1\"]\n",
        "data.head()"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Senten_count</th>\n",
              "      <th>length</th>\n",
              "      <th>word_count</th>\n",
              "      <th>UNQ_word_count</th>\n",
              "      <th>proc_text</th>\n",
              "      <th>NLTK_Pol</th>\n",
              "      <th>TB_Pol</th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Prob_Class_0</th>\n",
              "      <th>Prob_Class_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A good commentary of today's love and undoubte...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.310825</td>\n",
              "      <td>0.245822</td>\n",
              "      <td>0.245822</td>\n",
              "      <td>good commentary today love undoubtedly film wo...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.014585</td>\n",
              "      <td>0.985415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>For people who are first timers in film making...</td>\n",
              "      <td>1</td>\n",
              "      <td>5.296168</td>\n",
              "      <td>0.653339</td>\n",
              "      <td>0.664867</td>\n",
              "      <td>0.664867</td>\n",
              "      <td>people first timer film making think excellent...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.123060</td>\n",
              "      <td>0.876940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It was very popular when I was in the cinema, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>1.206632</td>\n",
              "      <td>1.363277</td>\n",
              "      <td>1.363277</td>\n",
              "      <td>wa popular wa cinema good house good reaction ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.020820</td>\n",
              "      <td>0.979180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It's a feel-good film and that's how I felt wh...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.416214</td>\n",
              "      <td>1.083913</td>\n",
              "      <td>1.083913</td>\n",
              "      <td>feel good film felt came cinema</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.097856</td>\n",
              "      <td>0.902144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It has northern humour and positive about the ...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.310825</td>\n",
              "      <td>-0.033542</td>\n",
              "      <td>-0.033542</td>\n",
              "      <td>ha northern humour positive community represents</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.488987</td>\n",
              "      <td>0.511013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  ...  Prob_Class_1\n",
              "0  A good commentary of today's love and undoubte...  ...      0.985415\n",
              "1  For people who are first timers in film making...  ...      0.876940\n",
              "2  It was very popular when I was in the cinema, ...  ...      0.979180\n",
              "3  It's a feel-good film and that's how I felt wh...  ...      0.902144\n",
              "4  It has northern humour and positive about the ...  ...      0.511013\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEIXERhtCexw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "9e52f7f4-65b5-43a0-d8db-ba927776591a"
      },
      "source": [
        "# build a dataset for misclassified instances\n",
        "data_analyse = data[((data[\"Polarity\"]==1) & (data[\"Prediction\"]==0)) | \n",
        "                    ((data[\"Polarity\"]==0) & (data[\"Prediction\"]==1)) ]\n",
        "\n",
        "data_analyse.reset_index(drop=True,inplace=True)\n",
        "data_analyse.head(20)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Senten_count</th>\n",
              "      <th>length</th>\n",
              "      <th>word_count</th>\n",
              "      <th>UNQ_word_count</th>\n",
              "      <th>proc_text</th>\n",
              "      <th>NLTK_Pol</th>\n",
              "      <th>TB_Pol</th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Prob_Class_0</th>\n",
              "      <th>Prob_Class_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Not too screamy not to masculine but just righ...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>-0.268815</td>\n",
              "      <td>-0.312906</td>\n",
              "      <td>-0.312906</td>\n",
              "      <td>screamy masculine right</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.534825</td>\n",
              "      <td>0.465175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I would have casted her in that role after rea...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.047352</td>\n",
              "      <td>0.106140</td>\n",
              "      <td>0.106140</td>\n",
              "      <td>would casted role ready script</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.710588</td>\n",
              "      <td>0.289412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The soundtrack wasn't terrible, either.</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>-0.505940</td>\n",
              "      <td>-0.731952</td>\n",
              "      <td>-0.731952</td>\n",
              "      <td>soundtrack terrible either</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.895719</td>\n",
              "      <td>0.104281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Still, it was the SETS that got a big \"10\" on ...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.152741</td>\n",
              "      <td>0.385503</td>\n",
              "      <td>0.385503</td>\n",
              "      <td>still wa set got big oy vey scale</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.806695</td>\n",
              "      <td>0.193305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The last 15 minutes of movie are also not bad ...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>-0.110732</td>\n",
              "      <td>-0.033542</td>\n",
              "      <td>-0.033542</td>\n",
              "      <td>last minute movie also bad well</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.927498</td>\n",
              "      <td>0.072502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I like Armand Assante &amp; my cable company's sum...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>1.838966</td>\n",
              "      <td>1.363277</td>\n",
              "      <td>1.363277</td>\n",
              "      <td>like armand assante cable company summary soun...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.860303</td>\n",
              "      <td>0.139697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>My 8/10 score is mostly for the plot.</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>-0.558635</td>\n",
              "      <td>-0.592270</td>\n",
              "      <td>-0.592270</td>\n",
              "      <td>score mostly plot</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.834270</td>\n",
              "      <td>0.165730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Not frightening in the least, and barely compr...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>-0.058037</td>\n",
              "      <td>-0.452588</td>\n",
              "      <td>-0.452588</td>\n",
              "      <td>frightening least barely comprehensible</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.484910</td>\n",
              "      <td>0.515090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Not even good for camp value!</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>-0.769413</td>\n",
              "      <td>-0.731952</td>\n",
              "      <td>-0.731952</td>\n",
              "      <td>even good camp value</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.188660</td>\n",
              "      <td>0.811340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I was deeply impressed with the character he p...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>-0.163426</td>\n",
              "      <td>-0.312906</td>\n",
              "      <td>-0.312906</td>\n",
              "      <td>wa deeply impressed character played</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.753737</td>\n",
              "      <td>0.246263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>The directing is sloppy at best.</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>-0.690371</td>\n",
              "      <td>-0.731952</td>\n",
              "      <td>-0.731952</td>\n",
              "      <td>directing sloppy best</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.259985</td>\n",
              "      <td>0.740015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>The acting by the whole cast could be put on a...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>1.391063</td>\n",
              "      <td>1.083913</td>\n",
              "      <td>1.083913</td>\n",
              "      <td>acting whole cast could put scale balanced per...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.462602</td>\n",
              "      <td>0.537398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>And, FINALLY, after all that, we get to an end...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>2.076091</td>\n",
              "      <td>2.061687</td>\n",
              "      <td>2.061687</td>\n",
              "      <td>finally get ending would great handled compete...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.026535</td>\n",
              "      <td>0.973465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>This movie was kind of long in length, but I e...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.363519</td>\n",
              "      <td>0.525185</td>\n",
              "      <td>0.525185</td>\n",
              "      <td>movie wa kind long length enjoyed every minute</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.589486</td>\n",
              "      <td>0.410514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Lifetime does not air it enough, so if anyone ...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>1.417410</td>\n",
              "      <td>1.642641</td>\n",
              "      <td>1.642641</td>\n",
              "      <td>lifetime doe air enough anyone know store sell...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.864423</td>\n",
              "      <td>0.135577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>This movie creates its own universe, and is fa...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.284477</td>\n",
              "      <td>0.106140</td>\n",
              "      <td>0.106140</td>\n",
              "      <td>movie creates universe fascinating every way</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.558799</td>\n",
              "      <td>0.441201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>But this movie really got to me.</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>-0.690371</td>\n",
              "      <td>-0.592270</td>\n",
              "      <td>-0.592270</td>\n",
              "      <td>movie really got</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.598883</td>\n",
              "      <td>0.401117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>See it.</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>-1.349053</td>\n",
              "      <td>-1.290680</td>\n",
              "      <td>-1.290680</td>\n",
              "      <td>see</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.644206</td>\n",
              "      <td>0.355794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>I really hope the team behind this movie makes...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>1.997050</td>\n",
              "      <td>2.061687</td>\n",
              "      <td>2.061687</td>\n",
              "      <td>really hope team behind movie make movie conti...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.749388</td>\n",
              "      <td>0.250612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Initially the local sites in the film, which w...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.732381</td>\n",
              "      <td>0.525185</td>\n",
              "      <td>0.525185</td>\n",
              "      <td>initially local site film wa filmed buffalo in...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.631326</td>\n",
              "      <td>0.368674</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Sentence  ...  Prob_Class_1\n",
              "0   Not too screamy not to masculine but just righ...  ...      0.465175\n",
              "1   I would have casted her in that role after rea...  ...      0.289412\n",
              "2           The soundtrack wasn't terrible, either.    ...      0.104281\n",
              "3   Still, it was the SETS that got a big \"10\" on ...  ...      0.193305\n",
              "4   The last 15 minutes of movie are also not bad ...  ...      0.072502\n",
              "5   I like Armand Assante & my cable company's sum...  ...      0.139697\n",
              "6             My 8/10 score is mostly for the plot.    ...      0.165730\n",
              "7   Not frightening in the least, and barely compr...  ...      0.515090\n",
              "8                     Not even good for camp value!    ...      0.811340\n",
              "9   I was deeply impressed with the character he p...  ...      0.246263\n",
              "10                 The directing is sloppy at best.    ...      0.740015\n",
              "11  The acting by the whole cast could be put on a...  ...      0.537398\n",
              "12  And, FINALLY, after all that, we get to an end...  ...      0.973465\n",
              "13  This movie was kind of long in length, but I e...  ...      0.410514\n",
              "14  Lifetime does not air it enough, so if anyone ...  ...      0.135577\n",
              "15  This movie creates its own universe, and is fa...  ...      0.441201\n",
              "16                 But this movie really got to me.    ...      0.401117\n",
              "17                                          See it.    ...      0.355794\n",
              "18  I really hope the team behind this movie makes...  ...      0.250612\n",
              "19  Initially the local sites in the film, which w...  ...      0.368674\n",
              "\n",
              "[20 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DRzVT48wfgh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "26ea2d37-fb8f-4c1f-9931-f54a7f34c686"
      },
      "source": [
        "# Analyse Wrong classification Use case 1\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[8,\"Sentence\"]),\n",
        "      check_sentiment(data_analyse.loc[8,\"Sentence\"]))\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[8,\"proc_text\"]),\n",
        "      check_sentiment(data_analyse.loc[8,\"proc_text\"]))\n",
        "\n",
        "print(data_analyse.loc[8,:],data_analyse.loc[8,\"Sentence\"])\n",
        "# Sentence Analysis\n",
        "# NLTK Sentiment analysis predicts positive \n",
        "# Textblob Sentiment analysis predicts neutral \n",
        "\n",
        "# Processed Text Analysis\n",
        "# NLTK Sentiment analysis predicts positive \n",
        "# Textblob Sentiment analysis predicts positive \n",
        "\n",
        "# Actual Polarity negative\n",
        "# Logistic Regression prediction positive\n",
        "# \n",
        "print(lr.intercept_,coef.loc[:,\"even\"],coef.loc[:,\"good\"],coef.loc[:,\"value\"])\n",
        "\n",
        "# Reason: Stopwords removed not which changes the tone of the text.\n",
        "# camp: not in BoW"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.875 -0.0767\n",
            "0.7 0.6486\n",
            "Sentence          Not even good for camp value!  \n",
            "Polarity                                        0\n",
            "Senten_count                            -0.184054\n",
            "length                                  -0.769413\n",
            "word_count                              -0.731952\n",
            "UNQ_word_count                          -0.731952\n",
            "proc_text                    even good camp value\n",
            "NLTK_Pol                                        1\n",
            "TB_Pol                                          1\n",
            "Prediction                                      1\n",
            "Prob_Class_0                              0.18866\n",
            "Prob_Class_1                              0.81134\n",
            "Name: 8, dtype: object Not even good for camp value!  \n",
            "[-0.36329847] 0    0.103056\n",
            "Name: even, dtype: float64 0    1.838707\n",
            "Name: good, dtype: float64 0   -0.119726\n",
            "Name: value, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyA8_hD2hCvu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "outputId": "6377ab2f-96c8-4462-87aa-1195607f66d1"
      },
      "source": [
        "# Analyse Wrong classification Use case 2\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[5,\"Sentence\"]),\n",
        "      check_sentiment(data_analyse.loc[5,\"Sentence\"]))\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[5,\"proc_text\"]),\n",
        "      check_sentiment(data_analyse.loc[5,\"proc_text\"]))\n",
        "\n",
        "print(data_analyse.loc[5,:],data_analyse.loc[5,\"Sentence\"])\n",
        "\n",
        "print(data_analyse.loc[5,\"proc_text\"])\n",
        "\n",
        "# Sentence Analysis\n",
        "# NLTK Sentiment analysis predicts positive \n",
        "# Textblob Sentiment analysis predicts positive \n",
        "\n",
        "# Processed Text Analysis\n",
        "# NLTK Sentiment analysis predicts positive \n",
        "# Textblob Sentiment analysis predicts positive \n",
        "\n",
        "# Actual Polarity positive\n",
        "# Logistic Regression prediction negative\n",
        "print(lr.intercept_,coef.loc[:,\"like\"],coef.loc[:,\"cable\"],coef.loc[:,\"company\"],\n",
        "      coef.loc[:,\"summary\"],coef.loc[:,\"sounded\"],coef.loc[:,\"interesting\"],\n",
        "      coef.loc[:,\"watched\"],coef.loc[:,\"twice\"],coef.loc[:,\"already\"],\n",
        "      coef.loc[:,\"probably\"])\n",
        "\n",
        "already_df = df_train.loc[df_train['Sentence'].str.contains(\"already\", case=False)]\n",
        "print(already_df.shape)\n",
        "already_df.Polarity.value_counts().plot.bar()\n",
        "\n",
        "# Reason: already has a very high negative coefficient. In the training dataset, \n",
        "# already was a feature only in 1 instance with polarity 0 thus coefficient was \n",
        "# negative A pre-trained model like NLTK, Textblob predicts the sentiment correctly\n",
        "# armand, assante: not in BoW"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5 0.6369\n",
            "0.5 0.6369\n",
            "Sentence          I like Armand Assante & my cable company's sum...\n",
            "Polarity                                                          1\n",
            "Senten_count                                              -0.184054\n",
            "length                                                      1.83897\n",
            "word_count                                                  1.36328\n",
            "UNQ_word_count                                              1.36328\n",
            "proc_text         like armand assante cable company summary soun...\n",
            "NLTK_Pol                                                          1\n",
            "TB_Pol                                                            1\n",
            "Prediction                                                        0\n",
            "Prob_Class_0                                               0.860303\n",
            "Prob_Class_1                                               0.139697\n",
            "Name: 5, dtype: object I like Armand Assante & my cable company's summary sounded interesting, so I watched it, twice already, and probably will again.  \n",
            "like armand assante cable company summary sounded interesting watched twice already probably\n",
            "[-0.36329847] 0    0.221132\n",
            "Name: like, dtype: float64 0   -0.192562\n",
            "Name: cable, dtype: float64 0   -0.361548\n",
            "Name: company, dtype: float64 0   -0.247707\n",
            "Name: summary, dtype: float64 0   -0.071925\n",
            "Name: sounded, dtype: float64 0    0.348372\n",
            "Name: interesting, dtype: float64 0   -0.163966\n",
            "Name: watched, dtype: float64 0    0.11963\n",
            "Name: twice, dtype: float64 0   -0.00213\n",
            "Name: already, dtype: float64 0   -1.103807\n",
            "Name: probably, dtype: float64\n",
            "(1, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb693602610>"
            ]
          },
          "metadata": {},
          "execution_count": 177
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jLkSdpntfvW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "outputId": "4dfce40c-7db2-4317-a79d-28edb03c2775"
      },
      "source": [
        "# Analyse Wrong classification Use case 3\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[2,\"Sentence\"]),\n",
        "      check_sentiment(data_analyse.loc[2,\"Sentence\"]))\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[2,\"proc_text\"]),\n",
        "      check_sentiment(data_analyse.loc[2,\"proc_text\"]))\n",
        "\n",
        "\n",
        "print(data_analyse.loc[2,:],data_analyse.loc[2,\"Sentence\"])\n",
        "\n",
        "print(data_analyse.loc[2,\"proc_text\"])\n",
        "\n",
        "# Sentence Analysis\n",
        "# NLTK Sentiment analysis predicts positive \n",
        "# Textblob Sentiment analysis predicts negative \n",
        "\n",
        "# Processed Text Analysis\n",
        "# NLTK Sentiment analysis predicts negative\n",
        "# Textblob Sentiment analysis predicts negative \n",
        "\n",
        "# Actual Polarity positive\n",
        "# Logistic Regression prediction negative\n",
        "print(lr.intercept_,coef.loc[:,\"soundtrack\"],coef.loc[:,\"terrible\"],coef.loc[:,\"either\"]) \n",
        "\n",
        "inp_df = df_train.loc[df_train['Sentence'].str.contains(\"soundtrack\", case=False)]\n",
        "print(inp_df.shape)\n",
        "# inp_df.Polarity.value_counts().plot.bar()\n",
        "# soundtrack has 2 instances: 1 with Polarity 1 and 1 with Polarity 0\n",
        "\n",
        "inp_df = df_train.loc[df_train['Sentence'].str.contains(\"terrible\", case=False)]\n",
        "print(inp_df.shape)\n",
        "inp_df.Polarity.value_counts().plot.bar()\n",
        "# terrible has 24 instances all with Polarity 0 \n",
        "\n",
        "# Reason: both soundtrack and terrible have negative coefficients. As keyword \n",
        "# wasnt was taken out due to stop word removal the pre-trained models are not \n",
        "# classifying the text correctly"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.0 0.3724\n",
            "-1.0 -0.4767\n",
            "Sentence          The soundtrack wasn't terrible, either.  \n",
            "Polarity                                                  1\n",
            "Senten_count                                      -0.184054\n",
            "length                                             -0.50594\n",
            "word_count                                        -0.731952\n",
            "UNQ_word_count                                    -0.731952\n",
            "proc_text                        soundtrack terrible either\n",
            "NLTK_Pol                                                  0\n",
            "TB_Pol                                                    0\n",
            "Prediction                                                0\n",
            "Prob_Class_0                                       0.895719\n",
            "Prob_Class_1                                       0.104281\n",
            "Name: 2, dtype: object The soundtrack wasn't terrible, either.  \n",
            "soundtrack terrible either\n",
            "[-0.36329847] 0   -0.144668\n",
            "Name: soundtrack, dtype: float64 0   -1.488657\n",
            "Name: terrible, dtype: float64 0   -0.15391\n",
            "Name: either, dtype: float64\n",
            "(2, 9)\n",
            "(24, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb6935f3150>"
            ]
          },
          "metadata": {},
          "execution_count": 178
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcSoe2lh-PyK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "outputId": "2ba42681-171a-4792-8234-1acf40c13441"
      },
      "source": [
        "# Analyse Wrong classification Use case 4\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[12,\"Sentence\"]),\n",
        "      check_sentiment(data_analyse.loc[12,\"Sentence\"]))\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[12,\"proc_text\"]),\n",
        "      check_sentiment(data_analyse.loc[12,\"proc_text\"]))\n",
        "\n",
        "print(data_analyse.loc[12,:],data_analyse.loc[12,[\"Sentence\"]])\n",
        "\n",
        "print(data_analyse.loc[12,\"proc_text\"])\n",
        "\n",
        "# Sentence Analysis\n",
        "# NLTK Sentiment analysis predicts positive \n",
        "# Textblob Sentiment analysis predicts positive \n",
        "\n",
        "# Processed Text Analysis\n",
        "# NLTK Sentiment analysis predicts positive \n",
        "# Textblob Sentiment analysis predicts positive \n",
        "\n",
        "# Actual Polarity negative\n",
        "# Logistic Regression prediction positive\n",
        "print(lr.intercept_,coef.loc[:,\"finally\"],coef.loc[:,\"get\"],coef.loc[:,\"ending\"],\n",
        "      coef.loc[:,\"would\"],coef.loc[:,\"great\"],coef.loc[:,\"handled\"],\n",
        "      coef.loc[:,\"handle\"],coef.loc[:,\"people\"])\n",
        "\n",
        "inp_df = df_train.loc[df_train['Sentence'].str.contains(\"would\", case=False)]\n",
        "print(inp_df.shape)\n",
        "inp_df.Polarity.value_counts().plot.bar()\n",
        "# would has 80 instances 52 with Polarity 0 and 28 with polarity 1\n",
        "\n",
        "# Reason: Would and get have high positive coefficients ideally I would expect \n",
        "# would post lemmatizer and stop word would be removed. A pre-trained model \n",
        "# like NLTK, Textblob predicts the sentiment correctly\n",
        "# jerry, falwell: not in BoW\n"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.43333333333333335 0.7506\n",
            "0.43333333333333335 0.7506\n",
            "Sentence          And, FINALLY, after all that, we get to an end...\n",
            "Polarity                                                          0\n",
            "Senten_count                                              -0.184054\n",
            "length                                                      2.07609\n",
            "word_count                                                  2.06169\n",
            "UNQ_word_count                                              2.06169\n",
            "proc_text         finally get ending would great handled compete...\n",
            "NLTK_Pol                                                          1\n",
            "TB_Pol                                                            1\n",
            "Prediction                                                        1\n",
            "Prob_Class_0                                              0.0265349\n",
            "Prob_Class_1                                               0.973465\n",
            "Name: 12, dtype: object Sentence    And, FINALLY, after all that, we get to an end...\n",
            "Name: 12, dtype: object\n",
            "finally get ending would great handled competent people jerry falwell\n",
            "[-0.36329847] 0   -0.012555\n",
            "Name: finally, dtype: float64 0    0.267567\n",
            "Name: get, dtype: float64 0    0.535653\n",
            "Name: ending, dtype: float64 0   -0.12188\n",
            "Name: would, dtype: float64 0    3.042869\n",
            "Name: great, dtype: float64 0    0.126579\n",
            "Name: handled, dtype: float64 0   -0.040793\n",
            "Name: handle, dtype: float64 0    0.127467\n",
            "Name: people, dtype: float64\n",
            "(80, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb69dc7af90>"
            ]
          },
          "metadata": {},
          "execution_count": 179
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2E68wzS-QRi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "outputId": "f460e023-eebc-4025-e895-9963c68ac2de"
      },
      "source": [
        "# Analyse Wrong classification Use case 5\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[30,\"Sentence\"]),\n",
        "      check_sentiment(data_analyse.loc[30,\"Sentence\"]))\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[30,\"proc_text\"]),\n",
        "      check_sentiment(data_analyse.loc[30,\"proc_text\"]))\n",
        "\n",
        "print(data_analyse.loc[30,:],data_analyse.loc[30,[\"Sentence\"]])\n",
        "\n",
        "print(data_analyse.loc[30,\"proc_text\"])\n",
        "\n",
        "# Sentence Analysis\n",
        "# NLTK Sentiment analysis predicts negative \n",
        "# Textblob Sentiment analysis predicts neutral \n",
        "\n",
        "# Processed Text Analysis\n",
        "# NLTK Sentiment analysis predicts positive \n",
        "# Textblob Sentiment analysis predicts neutral \n",
        "\n",
        "# Actual Polarity negative\n",
        "# Logistic Regression prediction positive\n",
        "print(lr.intercept_,coef.loc[:,\"recommended\"])\n",
        "\n",
        "rec_df = df_train.loc[df_train['Sentence'].str.contains(\"recommended\", case=False)]\n",
        "print(rec_df.shape)\n",
        "rec_df.Polarity.value_counts().plot.bar()\n",
        "\n",
        "# Reason: Not removed during stopword removal process which changes the meaning \n",
        "# of the sentence from not recommended to recommended. The pre-trained model may \n",
        "# be able to correctly predict the tone for the sentence but not for processed \n",
        "# text as the keyword is removed.\n"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 -0.1511\n",
            "0.0 0.2023\n",
            "Sentence          Not recommended.  \n",
            "Polarity                           0\n",
            "Senten_count               -0.184054\n",
            "length                      -1.11193\n",
            "word_count                  -1.29068\n",
            "UNQ_word_count              -1.29068\n",
            "proc_text                recommended\n",
            "NLTK_Pol                           1\n",
            "TB_Pol                             0\n",
            "Prediction                         1\n",
            "Prob_Class_0                 0.43171\n",
            "Prob_Class_1                 0.56829\n",
            "Name: 30, dtype: object Sentence    Not recommended.  \n",
            "Name: 30, dtype: object\n",
            "recommended\n",
            "[-0.36329847] 0    0.638175\n",
            "Name: recommended, dtype: float64\n",
            "(5, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb6935552d0>"
            ]
          },
          "metadata": {},
          "execution_count": 180
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}