{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "MMA865",
      "language": "python",
      "name": "mma865"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "MMA 2022W 865 Individual Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankxl/MMA865_Individual_Assignment/blob/main/MMA_2022W_865_Individual_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyZCMR6td1Mr"
      },
      "source": [
        "# MMA 2021S 865, Individual Assignment 1\n",
        "\n",
        "Version 2: Updated Janurary 13, 2021.\n",
        "\n",
        "- ANKIT RAI\n",
        "- 20254135\n",
        "- SECTION II\n",
        "- What The Ceo Really Wants From You by R Gopalakrishnan \n",
        "- 15 OCTOBER 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlGJQOaad1Ms"
      },
      "source": [
        "# Question 1 - ELI5\n",
        "\n",
        "_“If you can't explain it simply, you don't understand it well enough.” – Albert Einstein_\n",
        "\n",
        "Explaining technical concepts to a non-technical audience is an underappreciated skill; one which the MMA program aims to give its students; and one that will truly set you apart in the job market. The only way to gain a skill is by practice, so here we go.\n",
        "\n",
        "Answer each question below as though you were talking to a 5 year old (equivalently: a grandma, or a completely non-technical manager, or an Ivey grad). Use your own words. Use analogies where possible. Examples are better than theory. Keep it short, but be complete. Use simple, plain English. Do not use business buzzwords like _actualize, empower, fungible, leverage, or synergize_. Do not use technical buzzwords that most people don’t know like _model, agile, bandwidth, IoT, blockchain, AR, VR, actionable insights_. Inform the audience without going into too much technical detail, and without embarrassing yourself. Your goal is to truly help them understand, not to give what you feel is a “technically precise” answer and move on (but they still don’t understand!). Don’t be that guy!\n",
        "\n",
        "Please keep each answer to 1000 characters or less.\n",
        "\n",
        "Finally, feel free to use [Markdown syntax](https://www.markdownguide.org/basic-syntax/) to format your answer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9lm1L9bd1Mt"
      },
      "source": [
        "### Part 1: What is “Big Data” and how is it different than “regular data”?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvoA1AICd1Mu"
      },
      "source": [
        "\n",
        "1. As the word describes 'Big' data is often referring to the size of the data (Volume). Just imagine we want to record all conversations between a customer and retailer for a year. The conversations would be in hundreds of thousand or millions.\n",
        "2. Big data also is used to describe data which can not be stored in tabular format like text, images, etc. e.g., children story books or interaction that a person may have throughout the day or week or month. Variety in data.\n",
        "3. Data points collect every second or milisecond (almost realtime) also indicate big data (Velocity). e.g., commentary during a hockey or cricket match.\n",
        "4. Veracity: With large amount of data, checking for quality and consistencies is important like commentrator mentions some incorrect fact but might get missed in the volume or speed of incoming data.\n",
        "5. Value: There is no point in collecting big data unless we can derive value from it. Can we analyse the cricket match commentary and player data to devise a framework to get a batsman out (win the match)?\n",
        "\n",
        "- Examples of regular data: household budget or account statement. The budget can be depicted in columns with say date, description, transaction type and amount say 1st of month (date) received salary (description) in account (credited transaction type) and amount. Regular data is often not high volume or collected real time (not high velocity) and can be setup in tabular format like budget.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEKsagXWd1Mu"
      },
      "source": [
        "### Part 2: What is Hadoop? Hint: What problems in previous data storage and processing was Hadoop designed to solve? How did Hadoop accomplish that?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_0Fzj-od1Mu"
      },
      "source": [
        "We are planning a party for large number of guests. Hadoop is like the party planner which allows everyone to help to prepare for the party (open source) and doesnt need specific training from workers (community hardware). \n",
        "The usual problems that host face while planning party are:\n",
        "1. If the number of guest change at last minute, can planners accommodate without huge increase in bill (scale out).\n",
        "2. Things go wrong, like ingredients get spoiled, chef doesnt showup, will the party planner still deliver (fault tolerant).\n",
        "3. Will the planner move the ingredients from different locations to one cook station or setup different cooking stations near ingredient storage or serving location? (Move processing to data). \n",
        "4. While preparing salad does the chef preparing dressing need to worry about vegetable cut? (abstraction). \n",
        "\n",
        "Hadoop\n",
        "- Hadoop supports multiple chefs so the food is cooked simultanesouly (distributed compute). \n",
        "- If the hosts request to accommodate more guests or prepare food faster, Hadoop can add more chefs (scalability). \n",
        "- Hadoop gets more set of smaller pans versus large pans so that they can cook food simultaneously and makes it easier for them to carry and store. Depending upon need Hadoop adds pans (scale out).\n",
        "- Hadoop stores the ingredients at multiple locations so it is easier for chefs to cook in parallel (HDFS). \n",
        "-If for what ever reason the ingredients go bad, Hadoop stores ingredients in other locations and can easily get more (fault tolerant). \n",
        "- Hadoop has a party planning manager (YARN) which is responsible for identifying a lead for each item. e.g., for salad the manager identifies the chef 1 to be responsible for salad prep, chef 1 will ask chef 2 to cut veges, chef 4 to prepare dressing and chef 8 to toss the salad. In case chef 1 is unavailable, party manager will replace him.\n",
        "- If we are serving hot grilled fish for 100 guests, we can’t do it with 1 cook. Hadoop splits this into 10 cook station (map it across multiple compute) and waiters bring the fish from different location to one serving locations (reduce function).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWesjpN8d1Mv"
      },
      "source": [
        "### Part 3: How does Big Data and the cloud help Machine Learning? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAJS3UzNd1Mv"
      },
      "source": [
        "- Lets imaginge we need to move house. We need to book a truck to move goods and if we need to store for a day, we will need to rent a storage for a week. This is a costly investment and inefficient - truck used for an hour but paid for per day.\n",
        "- Let’s imagine cloud like a moving service which allows you to choose the level of support\n",
        ">- Basic (IaaS): where you pay only for amount of time you use the truck and storage unit.\n",
        ">- Advanced (PaaS): where you only get your furniture and dont must worry about loading/ unloading or refueling the truck.\n",
        ">- Complete (SaaS): where provider manages task end to end as desired by you. \n",
        "\n",
        "The key advantages of using Big Data and Cloud in ML are:\n",
        ">- Cost effective: billing is dependent on truck and storage usage per time unit instead of having to rent the truck and storage for day(s). You can also choose your truck depending upon need.\n",
        ">- As the services are cost effective one can start with a small pilot and then scale up if satisfied with performance.\n",
        ">- AI/ ML tools by public cloud providers: moving services company provides differnt services for different user (disabled versus professional movers) but support everyone.\n",
        ">- Ecosystem: lot of other companies offering different add ons like move furtniture through stairs of specific product for rent to move threadmill, etc.\n",
        ">- End to End pipeline: Cloud provides tools not just for building ML solutions but also visualise the output so in our analogy not just move the furniture but unwrap and place it in the right room as desired by user.\n",
        ">- Volume, Variety and Velocity (Big Data): Increase in data can increase the accuracy of machine learning e.g., the more books you read about a topic the more you will understand. Most of real-world data resides in unstructured format like audio or natural text or images and we can take advantage of AI/ML tools by public cloud providers and power of ecosystem to analyse data (described above). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blzNZpsKd1Mw"
      },
      "source": [
        "### Part 4: What is NoSQL?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euQZjTFDd1Mx"
      },
      "source": [
        "NoSQL is also referred as non-relational database. If we can not store data in rows and columns - like bank account statement can be represented in a table- then we need NoSQL e.g.  commentary of a match. There are 4 kinds of NoSQL based on use cases:\n",
        "- Key-value datastore: The easiest example to describe this is dictionary. The dictionary has a key word we are looking up and value is the definition. The keys are indexed alphabetically so its very easy to find the key.\n",
        "- Graph datastore: optimised for network analytics use case. Let say we want to build a family tree and identify the people family knows this datastore would be recommended. \n",
        "- Document datastore: Is a variant of the key value datastore with key difference being in value which is a file format. This is used extensively in applications like storing resume information. The key may be your name and value will be skills, education details, certifications and experience but saved in defined format like XML or JSON.\n",
        "- Columnar: Is very similar to relational database. Let’s take example of bank statement to highlight the advantage of columnar datastore. If user wants to understand all withdrawls from account in the last 1 year, the bank clerk will pull all the data with date of transaction on rows along with amount credited/ debited and transaction type. The computer will have to read through all the rows and columns before sharing result but in columnar data there is one row for date, amount transacted, transaction type and description. The query will only read through rows of interest like transaction amount and type. These speeds up the querying process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgbTZ0exbUk4"
      },
      "source": [
        "### Part 5: Name three ways topic modeling could help a bank."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etDOfiIud1Mx"
      },
      "source": [
        "Topic Modelling is the ability of algorithm/ machine to understand general idea of the message without having the ability to understand the message.\n",
        "\n",
        "1. Organise customer reviews (website, social media, telephonic chat) to identify key themes. The bank may be able to seperate the feedback specific to product or service improvement, bank operations, customer experience, etc. and appropriately act or not to act.\n",
        "2. Customers tend to read about investment products like MF report or equity research report before they invest. Topic modelling based on previous reading patterns can recommend investment products. If a customer is reading research on energy and banking stocks, the model may recommend an MF/ ETF on dividend stocks.\n",
        "3. Data reduction and Information Retrieval: Bank request their customer to call an agent to cancel specific services but sometimes customer to get a better deal (negotiating tactics) call the agent claiming to cancel not intending to cancel. Topic Modelling can mine for specific words or phrases in conversation that will indicate to agent if the customer has a high likelihood to cancel thus should offer discounted services or just negotiating for a better deal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2raqwCjwd1My"
      },
      "source": [
        "### Part 6: What is Apache Spark, exactly, and what are its pros and cons?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4Bc2UBRd1My"
      },
      "source": [
        "Spark is an open-source framework (describe above) that is used for data processing on large datasets leveraging multiple languages. \n",
        "\n",
        "Pros\n",
        "- Support multiple languages like Python, R, Scala, and SQL. e.g., let’s say the system understands French, German, and English; anyone who knows any of the languages can communicate with the system without translation. Spark can distribute python/ R code through user defined functions.\n",
        "- Reduces the number of read and write to/ from memory to reduce the speed of operations. Support all in memory. e.g., like trying to find something in a book without an index and we dont know which book or section of the library the book is in versus finding something in the book in front of you which has an index.\n",
        "- Easier to write applications. Earlier to get compute to execute map-reduce function was multiple lines of complex code whereas with spark it in 2-3 lines of simple code. E.g., we can divide two numbers using the long division route which may take a couple of minutes or just evaluate on a calculator which will be milliseconds.\n",
        "- Support for Big Data. Natural language processing and graph processing capabilities.\n",
        "Cons\n",
        "- requires re-learn python as pyspark. It can be a steep learning curve for new analyst as the code is not exactly same for python and pyspark. E.g., cricket player becoming a baseball player, there will be steep learning curve to understand the rules of the game and develop skill to excel.\n",
        "- Fewer ML algorithm. E.g., imagine a calculator with only + and – operations so if you want to calculate a square root it may be beyond the capability and may want to focus on another way to perform desired operation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uiuc0Wa2d1My"
      },
      "source": [
        "# Question 2: Sentiment Analysis via the ML-based approach\n",
        "\n",
        "Download the “Product Sentiment” dataset from the course portal: sentiment_train.csv and sentiment_test.csv."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv5daIZld1My"
      },
      "source": [
        "### Part 1.a. Loading and Prep\n",
        "\n",
        "Load, clean, and preprocess the data as you find necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjmNEojQd1Mz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d7dfb48-2ed6-4822-8074-70e3a7018e84"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# TODO: import other libraries as necessary\n",
        "\n",
        "# Load the training set data\n",
        "df_train = pd.read_csv(\"sentiment_train.csv\")\n",
        "# Analyse the training data: Columns and data type; first 5 rows of data\n",
        "print(df_train.info())\n",
        "print(df_train.head())\n",
        "\n",
        "# Load the testing data\n",
        "df_test = pd.read_csv(\"sentiment_test.csv\")\n",
        "\n",
        "# Analyse the testing data: Columns and data type; first 5 rows of data\n",
        "print(df_test.info())\n",
        "print(df_test.head())\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2400 entries, 0 to 2399\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  2400 non-null   object\n",
            " 1   Polarity  2400 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 37.6+ KB\n",
            "None\n",
            "                                            Sentence  Polarity\n",
            "0                           Wow... Loved this place.         1\n",
            "1                                 Crust is not good.         0\n",
            "2          Not tasty and the texture was just nasty.         0\n",
            "3  Stopped by during the late May bank holiday of...         1\n",
            "4  The selection on the menu was great and so wer...         1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 600 entries, 0 to 599\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  600 non-null    object\n",
            " 1   Polarity  600 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 9.5+ KB\n",
            "None\n",
            "                                            Sentence  Polarity\n",
            "0  A good commentary of today's love and undoubte...         1\n",
            "1  For people who are first timers in film making...         1\n",
            "2  It was very popular when I was in the cinema, ...         1\n",
            "3  It's a feel-good film and that's how I felt wh...         1\n",
            "4  It has northern humour and positive about the ...         1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COPEmCCSd1M0"
      },
      "source": [
        "### Part 1.b. Modeling\n",
        "\n",
        "Use your favorite ML algorithm to train a classification model.  Don’t forget everything that we’ve learned in our ML course: hyperparameter tuning, cross validation, handling imbalanced data, etc. Make reasonable decisions and try to create the best-performing classifier that you can."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNbnyhF_in7K"
      },
      "source": [
        "## Basic Data check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY0wtbVwd1M0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cee8f0f-2e14-4f5d-eef4-569bd7ebd86b"
      },
      "source": [
        "# Check for Missing values in data\n",
        "df_train.isna().sum()\n",
        "# df_test.isna().sum()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence    0\n",
              "Polarity    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkPQTGFyfk_s",
        "outputId": "236807c5-a9d3-4197-b177-f6637c9b197f"
      },
      "source": [
        "# Check for balance in train dataset\n",
        "df_train[\"Polarity\"].value_counts()\n",
        "# df_test.groupby(\"Polarity\").count()\n",
        "\n",
        "# The weights are almost equal, will leverage class weight of ML algorithm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1213\n",
              "1    1187\n",
              "Name: Polarity, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "6YVk30CewiMa",
        "outputId": "8aa1dc67-892f-4b3e-e4dc-f689a50f4c1c"
      },
      "source": [
        "df_train[\"Polarity\"].value_counts().plot.bar()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f56716734d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD1CAYAAAC87SVQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANt0lEQVR4nO3df6jd9X3H8edrZrq1BaPmEjRJl0DTFTsYlYt1CFtptvqjZfGPVnRlZi4QBrq1c1Dj9oewUVA26iorQmiyRnBacR2GztVlUSljaL22Yo2p82KruUHNbY3uh3Q27Xt/3I94er3JTe65OVfzeT7gcr/fz/dzzvdzIDzv4Xu/5yZVhSSpD7+w1AuQJI2O0Zekjhh9SeqI0Zekjhh9SeqI0Zekjixb6gUczYoVK2rt2rVLvQxJekd57LHHflhVY3Mde1tHf+3atUxMTCz1MiTpHSXJc0c65uUdSeqI0Zekjhh9SeqI0Zekjhh9SeqI0Zekjhh9SerIvNFPsiPJwSRPDoz9dZLvJXkiyT8lWT5w7IYkk0meTnLRwPjFbWwyydbFfymSpPkcy4ezvgL8HXD7wNhu4IaqOpzkZuAG4Pok5wJXAB8EzgH+Lcn722O+BPwOMAU8mmRXVT21OC9jaa3d+s9LvYSTyg9u+vhSL0E6ac37Tr+qvgm8PGvsX6vqcNt9GFjdtjcCd1XV/1XV94FJ4Pz2NVlVz1bV68Bdba4kaYQW45r+HwL/0rZXAfsHjk21sSONS5JGaKjoJ/kL4DBwx+IsB5JsSTKRZGJ6enqxnlaSxBDRT/IHwCeAT9eb/7v6AWDNwLTVbexI429RVduqaryqxsfG5vwjcZKkBVrQX9lMcjHwOeC3quq1gUO7gH9I8gVmfpG7HvgWEGB9knXMxP4K4PeGWbikY+ONBovnZLjJYN7oJ7kT+AiwIskUcCMzd+ucBuxOAvBwVf1RVe1NcjfwFDOXfa6pqp+257kWuB84BdhRVXtPwOuRJB3FvNGvqivnGN5+lPmfBz4/x/h9wH3HtTpJ0qLyE7mS1BGjL0kdMfqS1BGjL0kdMfqS1BGjL0kdMfqS1BGjL0kdMfqS1BGjL0kdMfqS1BGjL0kdMfqS1BGjL0kdMfqS1BGjL0kdMfqS1BGjL0kdMfqS1BGjL0kdMfqS1BGjL0kdMfqS1BGjL0kdMfqS1JF5o59kR5KDSZ4cGDszye4kz7TvZ7TxJLk1yWSSJ5KcN/CYTW3+M0k2nZiXI0k6mmN5p/8V4OJZY1uBPVW1HtjT9gEuAda3ry3AbTDzQwK4EfgwcD5w4xs/KCRJozNv9Kvqm8DLs4Y3Ajvb9k7gsoHx22vGw8DyJGcDFwG7q+rlqjoE7OatP0gkSSfYQq/pr6yqF9r2i8DKtr0K2D8wb6qNHWlckjRCQ/8it6oKqEVYCwBJtiSZSDIxPT29WE8rSWLh0X+pXbahfT/Yxg8AawbmrW5jRxp/i6raVlXjVTU+Nja2wOVJkuay0OjvAt64A2cTcO/A+FXtLp4LgFfbZaD7gY8lOaP9AvdjbUySNELL5puQ5E7gI8CKJFPM3IVzE3B3ks3Ac8Dlbfp9wKXAJPAacDVAVb2c5K+AR9u8v6yq2b8cliSdYPNGv6quPMKhDXPMLeCaIzzPDmDHca1OkrSo/ESuJHXE6EtSR4y+JHXE6EtSR4y+JHXE6EtSR4y+JHXE6EtSR4y+JHXE6EtSR4y+JHXE6EtSR4y+JHXE6EtSR4y+JHXE6EtSR4y+JHXE6EtSR4y+JHXE6EtSR4y+JHXE6EtSR4y+JHXE6EtSR4y+JHVkqOgn+dMke5M8meTOJL+UZF2SR5JMJvlqklPb3NPa/mQ7vnYxXoAk6dgtOPpJVgF/AoxX1a8BpwBXADcDt1TV+4BDwOb2kM3AoTZ+S5snSRqhYS/vLAN+Ocky4F3AC8BHgXva8Z3AZW17Y9unHd+QJEOeX5J0HBYc/ao6APwN8DwzsX8VeAx4paoOt2lTwKq2vQrY3x57uM0/a6HnlyQdv2Eu75zBzLv3dcA5wLuBi4ddUJItSSaSTExPTw/7dJKkAcNc3vlt4PtVNV1VPwG+BlwILG+XewBWAwfa9gFgDUA7fjrwo9lPWlXbqmq8qsbHxsaGWJ4kabZhov88cEGSd7Vr8xuAp4AHgU+2OZuAe9v2rrZPO/5AVdUQ55ckHadhruk/wswvZL8NfLc91zbgeuC6JJPMXLPf3h6yHTirjV8HbB1i3ZKkBVg2/5Qjq6obgRtnDT8LnD/H3B8DnxrmfJKk4fiJXEnqiNGXpI4YfUnqiNGXpI4YfUnqiNGXpI4YfUnqiNGXpI4YfUnqiNGXpI4YfUnqiNGXpI4YfUnqiNGXpI4YfUnqiNGXpI4YfUnqiNGXpI4YfUnqiNGXpI4YfUnqiNGXpI4YfUnqiNGXpI4YfUnqyFDRT7I8yT1JvpdkX5LfSHJmkt1Jnmnfz2hzk+TWJJNJnkhy3uK8BEnSsRr2nf4XgW9U1QeAXwf2AVuBPVW1HtjT9gEuAda3ry3AbUOeW5J0nBYc/SSnA78JbAeoqter6hVgI7CzTdsJXNa2NwK314yHgeVJzl7wyiVJx22Yd/rrgGng75N8J8mXk7wbWFlVL7Q5LwIr2/YqYP/A46famCRpRIaJ/jLgPOC2qvoQ8L+8eSkHgKoqoI7nSZNsSTKRZGJ6enqI5UmSZhsm+lPAVFU90vbvYeaHwEtvXLZp3w+24weANQOPX93Gfk5Vbauq8aoaHxsbG2J5kqTZFhz9qnoR2J/kV9vQBuApYBewqY1tAu5t27uAq9pdPBcArw5cBpIkjcCyIR//x8AdSU4FngWuZuYHyd1JNgPPAZe3ufcBlwKTwGttriRphIaKflU9DozPcWjDHHMLuGaY80mShuMnciWpI0Zfkjpi9CWpI0Zfkjpi9CWpI0Zfkjpi9CWpI0Zfkjpi9CWpI0Zfkjpi9CWpI0Zfkjpi9CWpI0Zfkjpi9CWpI0Zfkjpi9CWpI0Zfkjpi9CWpI0Zfkjpi9CWpI0Zfkjpi9CWpI0Zfkjpi9CWpI0NHP8kpSb6T5Ottf12SR5JMJvlqklPb+Gltf7IdXzvsuSVJx2cx3ul/Btg3sH8zcEtVvQ84BGxu45uBQ238ljZPkjRCQ0U/yWrg48CX236AjwL3tCk7gcva9sa2Tzu+oc2XJI3IsO/0/xb4HPCztn8W8EpVHW77U8Cqtr0K2A/Qjr/a5kuSRmTB0U/yCeBgVT22iOshyZYkE0kmpqenF/OpJal7w7zTvxD43SQ/AO5i5rLOF4HlSZa1OauBA237ALAGoB0/HfjR7Cetqm1VNV5V42NjY0MsT5I024KjX1U3VNXqqloLXAE8UFWfBh4EPtmmbQLubdu72j7t+ANVVQs9vyTp+J2I+/SvB65LMsnMNfvtbXw7cFYbvw7YegLOLUk6imXzT5lfVT0EPNS2nwXOn2POj4FPLcb5JEkL4ydyJakjRl+SOmL0JakjRl+SOmL0JakjRl+SOmL0JakjRl+SOmL0JakjRl+SOmL0JakjRl+SOmL0JakjRl+SOmL0JakjRl+SOmL0JakjRl+SOmL0JakjRl+SOmL0JakjRl+SOmL0JakjRl+SOmL0JakjC45+kjVJHkzyVJK9ST7Txs9MsjvJM+37GW08SW5NMpnkiSTnLdaLkCQdm2He6R8G/qyqzgUuAK5Jci6wFdhTVeuBPW0f4BJgffvaAtw2xLklSQuw4OhX1QtV9e22/d/APmAVsBHY2abtBC5r2xuB22vGw8DyJGcveOWSpOO2KNf0k6wFPgQ8AqysqhfaoReBlW17FbB/4GFTbUySNCJDRz/Je4B/BD5bVf81eKyqCqjjfL4tSSaSTExPTw+7PEnSgKGin+QXmQn+HVX1tTb80huXbdr3g238ALBm4OGr29jPqaptVTVeVeNjY2PDLE+SNMswd+8E2A7sq6ovDBzaBWxq25uAewfGr2p38VwAvDpwGUiSNALLhnjshcDvA99N8ngb+3PgJuDuJJuB54DL27H7gEuBSeA14Oohzi1JWoAFR7+q/h3IEQ5vmGN+Adcs9HySpOH5iVxJ6ojRl6SOGH1J6ojRl6SOGH1J6ojRl6SOGH1J6ojRl6SOGH1J6ojRl6SOGH1J6ojRl6SOGH1J6ojRl6SOGH1J6ojRl6SOGH1J6ojRl6SOGH1J6ojRl6SOGH1J6ojRl6SOGH1J6ojRl6SOGH1J6ojRl6SOjDz6SS5O8nSSySRbR31+SerZSKOf5BTgS8AlwLnAlUnOHeUaJKlno36nfz4wWVXPVtXrwF3AxhGvQZK6tWzE51sF7B/YnwI+PDghyRZgS9v9nyRPj2htPVgB/HCpFzGf3LzUK9ASedv/+3wH/dv8lSMdGHX051VV24BtS72Ok1GSiaoaX+p1SHPx3+dojPryzgFgzcD+6jYmSRqBUUf/UWB9knVJTgWuAHaNeA2S1K2RXt6pqsNJrgXuB04BdlTV3lGuoXNeNtPbmf8+RyBVtdRrkCSNiJ/IlaSOGH1J6ojRl6SOvO3u09fiSfIBZj7xvKoNHQB2VdW+pVuVpKXkO/2TVJLrmfkzFwG+1b4C3OkfutPbWZKrl3oNJzPv3jlJJflP4INV9ZNZ46cCe6tq/dKsTDq6JM9X1XuXeh0nKy/vnLx+BpwDPDdr/Ox2TFoySZ440iFg5SjX0hujf/L6LLAnyTO8+Ufu3gu8D7h2yVYlzVgJXAQcmjUe4D9Gv5x+GP2TVFV9I8n7mflz1oO/yH20qn66dCuTAPg68J6qenz2gSQPjX45/fCaviR1xLt3JKkjRl+SOmL0JakjRl+SOmL0Jakj/w+9vkD1tOOVZgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd4fYOaoflwu",
        "outputId": "cb4cf3bc-b801-4862-b564-a4cca78a668e"
      },
      "source": [
        "# check for duplicate sentences\n",
        "df_train.duplicated(subset=[\"Sentence\"]).sum()\n",
        "# df_test.duplicated(subset=[\"Sentence\"]).sum()\n",
        "\n",
        "# There are 18 duplicates in the training dataset"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMuv1q81LrPs"
      },
      "source": [
        "# drop the 18 duplicates indentified in previous step\n",
        "df_train = df_train.drop_duplicates(subset=[\"Sentence\"],keep=\"last\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKB5QA2Ofl09",
        "outputId": "3a835c3f-11de-41fd-dd56-9417f7a1d67a"
      },
      "source": [
        "# Re-Check for balance in train dataset after deleting duplicate sentences\n",
        "df_train[\"Polarity\"].value_counts()\n",
        "\n",
        "# The weights are still almost equal, will leverage class weight of ML algorithm. \n",
        "# 7 instances from class 0 were dropped and 11 instances for class 1 were dropped "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1206\n",
              "1    1176\n",
              "Name: Polarity, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "zJdcvyKKfl4B",
        "outputId": "89212e17-18d4-48fa-fb58-87bc9a9cffdc"
      },
      "source": [
        "df_train.describe().transpose()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Polarity</th>\n",
              "      <td>2382.0</td>\n",
              "      <td>0.493703</td>\n",
              "      <td>0.500065</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count      mean       std  min  25%  50%  75%  max\n",
              "Polarity  2382.0  0.493703  0.500065  0.0  0.0  0.0  1.0  1.0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5eHc4JTiyq3"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UEXfbx8fl7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36fc19b8-75c0-4e73-fc51-18d3c776f3c8"
      },
      "source": [
        "# Import NLTK module and download the necessary collections \n",
        "# (commenting download for output generation)\n",
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX5y7bbDi5Xb"
      },
      "source": [
        "# New Feature: Total number of sentences for each text in training and test dataset.\n",
        "\n",
        "def Tokenize(x):\n",
        "    return len(nltk.sent_tokenize(x))\n",
        "\n",
        "df_train['Senten_count'] = df_train['Sentence'].apply(lambda x: Tokenize(x))\n",
        "df_test['Senten_count'] = df_test['Sentence'].apply(lambda x: Tokenize(x))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-55T-1jY0Jwf"
      },
      "source": [
        "# New Feature: Total number of characters for each text in training and test dataset.\n",
        "\n",
        "def length(x):\n",
        "    return len(x)\n",
        "\n",
        "df_train['length'] = df_train['Sentence'].apply(lambda x: length(x))\n",
        "df_test['length'] = df_test['Sentence'].apply(lambda x: length(x))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVngYg1gtLzV"
      },
      "source": [
        "# New Feature: Total number of words for each text in training and test dataset.\n",
        "\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def counter(x):\n",
        "  r = re.sub('[^a-zA-Z]', ' ', x)\n",
        "  r = r.lower()\n",
        "  r = r.split()\n",
        "  word_count = len(r)\n",
        "  return word_count\n",
        "\n",
        "df_train[\"word_count\"] = df_train['Sentence'].apply(lambda x: counter(x))\n",
        "\n",
        "df_test[\"word_count\"] = df_test['Sentence'].apply(lambda x: counter(x))\n",
        "\n",
        "# New Feature: Total number of unique words for each text in training and test dataset.\n",
        "\n",
        "def UNQ_counter(x):\n",
        "  r = re.sub('[^a-zA-Z]', ' ', x)\n",
        "  r = r.lower()\n",
        "  r = r.split()\n",
        "  word_count = len(r)\n",
        "  unique_word_count = len(set(r))\n",
        "  return word_count\n",
        "\n",
        "df_train[\"UNQ_word_count\"] = df_train['Sentence'].apply(lambda x: UNQ_counter(x))\n",
        "\n",
        "df_test[\"UNQ_word_count\"] = df_test['Sentence'].apply(lambda x: UNQ_counter(x))\n",
        "\n",
        "# New Feature: Build processed text with following features:\n",
        "# 1. replace non alphabet text with spaces\n",
        "# 2. convert text in to lower case\n",
        "# 3. split in to tokens by using default (spaces)\n",
        "# 4. use lemmatizer to lemmatize words\n",
        "# 5. Remove stopwords\n",
        "# 6. re-join the remaining tokens using spaces\n",
        "# 7. Create a new feature called proc_text in training and text dataset \n",
        "\n",
        "\n",
        "def text_processing(x):\n",
        "  r = re.sub('[^a-zA-Z]', ' ', x)\n",
        "  r = r.lower()\n",
        "  r = r.split()\n",
        "  word_count = len(r)\n",
        "  unique_word_count = len(set(r))\n",
        "  r = [lemmatizer.lemmatize(word) for word in r]\n",
        "  r = [word for word in r if word not in stopwords.words('english')]\n",
        "  r = ' '.join(r)\n",
        "  return r\n",
        "\n",
        "df_train[\"proc_text\"] = df_train['Sentence'].apply(lambda x: text_processing(x))\n",
        "\n",
        "df_test[\"proc_text\"] = df_test['Sentence'].apply(lambda x: text_processing(x))\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "CN1nMnJL1tP3",
        "outputId": "bbff4143-a28d-47e1-eff8-bb2bc48772a9"
      },
      "source": [
        "df_train.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Senten_count</th>\n",
              "      <th>length</th>\n",
              "      <th>word_count</th>\n",
              "      <th>UNQ_word_count</th>\n",
              "      <th>proc_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>wow loved place</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>crust good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>tasty texture wa nasty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>stopped late may bank holiday rick steve recom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>selection menu wa great price</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  ...                                          proc_text\n",
              "0                           Wow... Loved this place.  ...                                    wow loved place\n",
              "1                                 Crust is not good.  ...                                         crust good\n",
              "2          Not tasty and the texture was just nasty.  ...                             tasty texture wa nasty\n",
              "3  Stopped by during the late May bank holiday of...  ...  stopped late may bank holiday rick steve recom...\n",
              "4  The selection on the menu was great and so wer...  ...                      selection menu wa great price\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "TSeWEfSDljRI",
        "outputId": "1d0650af-f1eb-4b5f-ece4-9da44922a460"
      },
      "source": [
        "# Analyse the histogram for length of text (characters in string) for each Polarity class\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.xscale('log')\n",
        "bins = 1.15**(np.arange(0,50))\n",
        "plt.hist(df_train[df_train['Polarity']==0]['length'],bins=bins,alpha=0.8)\n",
        "plt.hist(df_train[df_train['Polarity']==1]['length'],bins=bins,alpha=0.8)\n",
        "plt.legend(('class 0','class 1'))\n",
        "plt.show()\n",
        "\n",
        "# The histogram doesnt yield any distinguishable insights"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "G-Rcgpn3oX6B",
        "outputId": "16ff349a-ab58-4f6b-8caf-3f4ea45d6504"
      },
      "source": [
        "# Analyse the histogram for word count for each Polarity class\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# plt.xscale('log')\n",
        "bins = 1.2**(np.arange(0,25))\n",
        "plt.hist(df_train[df_train['Polarity']==0]['word_count'],bins=bins,alpha=0.8)\n",
        "plt.hist(df_train[df_train['Polarity']==1]['word_count'],bins=bins,alpha=0.8)\n",
        "plt.legend(('class 0','class 1'))\n",
        "plt.show()\n",
        "\n",
        "# The histogram doesnt yield any distinguishable insights"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "-OPftWAy1cDE",
        "outputId": "c620daf5-0084-4f68-e19d-26cc6f6a5e5f"
      },
      "source": [
        "# Analyse the histogram for unique word count for each Polarity class\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# plt.xscale('log')\n",
        "bins = 1.2**(np.arange(0,25))\n",
        "plt.hist(df_train[df_train['Polarity']==0]['UNQ_word_count'],bins=bins,alpha=0.8)\n",
        "plt.hist(df_train[df_train['Polarity']==1]['UNQ_word_count'],bins=bins,alpha=0.8)\n",
        "plt.legend(('class 0','class 1'))\n",
        "plt.show()\n",
        "\n",
        "# The histogram doesnt yield any distinguishable insights"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "MokL4eH11cOv",
        "outputId": "51a5e986-33f8-42bd-e247-27f1daf7d7c3"
      },
      "source": [
        "# Analyse the histogram for number of sentences for each Polarity class\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# plt.xscale('log')\n",
        "bins = 1.2**(np.arange(0,10))\n",
        "plt.hist(df_train[df_train['Polarity']==0]['Senten_count'],bins=bins,alpha=0.5)\n",
        "plt.hist(df_train[df_train['Polarity']==1]['Senten_count'],bins=bins,alpha=0.5)\n",
        "plt.legend(('class 0','class 1'))\n",
        "plt.show()\n",
        "\n",
        "# The histogram doesnt yield any distinguishable insights"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCHhkHKtaoH_"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2nHFLm3Gaou_",
        "outputId": "6dcbcd15-d39c-42ba-b722-d9b3b8f59858"
      },
      "source": [
        "# Scale the new features as number of sentences range from 1 to 2 while the number of characters range to the 100's\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "df_train[[\"Senten_count\",\"length\",\"word_count\",\"UNQ_word_count\"]] = scaler.fit_transform(df_train[[\"Senten_count\",\"length\",\"word_count\",\"UNQ_word_count\"]])\n",
        "df_train.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Senten_count</th>\n",
              "      <th>length</th>\n",
              "      <th>word_count</th>\n",
              "      <th>UNQ_word_count</th>\n",
              "      <th>proc_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "      <td>5.296168</td>\n",
              "      <td>-0.953844</td>\n",
              "      <td>-1.011316</td>\n",
              "      <td>-1.011316</td>\n",
              "      <td>wow loved place</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>-1.111928</td>\n",
              "      <td>-1.011316</td>\n",
              "      <td>-1.011316</td>\n",
              "      <td>crust good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>-0.505940</td>\n",
              "      <td>-0.452588</td>\n",
              "      <td>-0.452588</td>\n",
              "      <td>tasty texture wa nasty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.706034</td>\n",
              "      <td>0.525185</td>\n",
              "      <td>0.525185</td>\n",
              "      <td>stopped late may bank holiday rick steve recom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>-0.031690</td>\n",
              "      <td>0.106140</td>\n",
              "      <td>0.106140</td>\n",
              "      <td>selection menu wa great price</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  ...                                          proc_text\n",
              "0                           Wow... Loved this place.  ...                                    wow loved place\n",
              "1                                 Crust is not good.  ...                                         crust good\n",
              "2          Not tasty and the texture was just nasty.  ...                             tasty texture wa nasty\n",
              "3  Stopped by during the late May bank holiday of...  ...  stopped late may bank holiday rick steve recom...\n",
              "4  The selection on the menu was great and so wer...  ...                      selection menu wa great price\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "RSUXshJCbYm-",
        "outputId": "dd6bf273-6bb9-40ea-ad19-a592b12bfdd2"
      },
      "source": [
        "df_test[[\"Senten_count\",\"length\",\"word_count\",\"UNQ_word_count\"]] = scaler.transform(df_test[[\"Senten_count\",\"length\",\"word_count\",\"UNQ_word_count\"]])\n",
        "df_test.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Senten_count</th>\n",
              "      <th>length</th>\n",
              "      <th>word_count</th>\n",
              "      <th>UNQ_word_count</th>\n",
              "      <th>proc_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A good commentary of today's love and undoubte...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.310825</td>\n",
              "      <td>0.245822</td>\n",
              "      <td>0.245822</td>\n",
              "      <td>good commentary today love undoubtedly film wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>For people who are first timers in film making...</td>\n",
              "      <td>1</td>\n",
              "      <td>5.296168</td>\n",
              "      <td>0.653339</td>\n",
              "      <td>0.664867</td>\n",
              "      <td>0.664867</td>\n",
              "      <td>people first timer film making think excellent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It was very popular when I was in the cinema, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>1.206632</td>\n",
              "      <td>1.363277</td>\n",
              "      <td>1.363277</td>\n",
              "      <td>wa popular wa cinema good house good reaction ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It's a feel-good film and that's how I felt wh...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.416214</td>\n",
              "      <td>1.083913</td>\n",
              "      <td>1.083913</td>\n",
              "      <td>feel good film felt came cinema</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It has northern humour and positive about the ...</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.184054</td>\n",
              "      <td>0.310825</td>\n",
              "      <td>-0.033542</td>\n",
              "      <td>-0.033542</td>\n",
              "      <td>ha northern humour positive community represents</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  ...                                          proc_text\n",
              "0  A good commentary of today's love and undoubte...  ...  good commentary today love undoubtedly film wo...\n",
              "1  For people who are first timers in film making...  ...  people first timer film making think excellent...\n",
              "2  It was very popular when I was in the cinema, ...  ...  wa popular wa cinema good house good reaction ...\n",
              "3  It's a feel-good film and that's how I felt wh...  ...                    feel good film felt came cinema\n",
              "4  It has northern humour and positive about the ...  ...   ha northern humour positive community represents\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7muH59HoiHG"
      },
      "source": [
        "## Test Train Split for baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb_AhGvfogzS",
        "outputId": "80064821-193f-4a79-ceb6-c9a79e3aebb8"
      },
      "source": [
        "# split the training set for training and validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y = df_train.Polarity\n",
        "X = df_train.drop(\"Polarity\",axis=1)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, \n",
        "                                                    random_state=666)\n",
        "\n",
        "print('Training Data :', X_train.shape)\n",
        "print('Testing Data : ', X_test.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data : (1786, 6)\n",
            "Testing Data :  (596, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "piKW2oK7ohDG",
        "outputId": "0ae0fb79-c456-4804-c978-ac274d0d869e"
      },
      "source": [
        "y_train.value_counts().plot.bar()\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5656604950>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzdFmF2sPYQj"
      },
      "source": [
        "# Dataset for baseline splits\n",
        "X_train_b = X_train[[\"Senten_count\",\"length\",\"word_count\",\"UNQ_word_count\"]]\n",
        "X_test_b = X_test[[\"Senten_count\",\"length\",\"word_count\",\"UNQ_word_count\"]]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaADA3HpO1wN"
      },
      "source": [
        "## Baseline Model \n",
        "using features like Length, nos of Sentences, nos of words and nos of unique words "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U7y-C7YO2at",
        "outputId": "38bc8296-0b8e-4575-92b3-45cb2fc1a190"
      },
      "source": [
        "# Logistics regression as baseline model with class weights as balanced\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(class_weight=\"balanced\",random_state=666)\n",
        "lr.fit(X_train_b, y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=666, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4QjAOHJPPD0"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Create a prediction set:\n",
        "predictions = lr.predict(X_test_b)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFmHPvARPPP7",
        "outputId": "e37092f4-ead4-4b69-cab9-b93c49a64fe2"
      },
      "source": [
        "# classification report\n",
        "print(metrics.classification_report(y_test,predictions))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.47      0.52       310\n",
            "           1       0.52      0.63      0.57       286\n",
            "\n",
            "    accuracy                           0.55       596\n",
            "   macro avg       0.55      0.55      0.55       596\n",
            "weighted avg       0.55      0.55      0.54       596\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqSKjZQbP3Q5",
        "outputId": "4cfb8c13-7521-4098-bd39-fe7b451c8fda"
      },
      "source": [
        "from sklearn import metrics\n",
        "# Check AUC\n",
        "print(metrics.roc_auc_score(y_test,lr.predict_proba(X_test_b)[:, 1]))\n",
        "\n",
        "# the model is not good, just better than random guess"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5712271599368374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUXgORXxSuDR",
        "outputId": "6befd815-c076-46e8-e798-8e083db27350"
      },
      "source": [
        "# Check F1 Score\n",
        "print(metrics.f1_score(y_test,predictions))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5727848101265823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "v7NKxIZCP3Wn",
        "outputId": "975589a0-a076-4497-f6f8-5e805e68b5a0"
      },
      "source": [
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "cm = ConfusionMatrix(lr, classes=[0,1])\n",
        "cm.fit(X_train_b, y_train)\n",
        "cm.score(X_test_b, y_test)\n",
        "cm.poof();"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyFKGpNz6wcm"
      },
      "source": [
        "## Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQXx8shveHFx"
      },
      "source": [
        "# Create new features: Bag of Words based on processed text (not on original text)\n",
        "y = df_train.Polarity\n",
        "X = df_train.proc_text\n",
        "\n",
        "test = df_test.proc_text"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcKGaxiQohMX"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "cv = CountVectorizer()\n",
        "# tfidf = TfidfVectorizer() \n",
        "# TFIDF model gave a lower auc and f1"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVN4WkNaAGIf",
        "outputId": "3945b032-55b2-403e-ab26-72904993c19a"
      },
      "source": [
        "X.head(20)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                       wow loved place\n",
              "1                                            crust good\n",
              "2                                tasty texture wa nasty\n",
              "3     stopped late may bank holiday rick steve recom...\n",
              "4                         selection menu wa great price\n",
              "5                           getting angry want damn pho\n",
              "6                                  honeslty taste fresh\n",
              "7     potato like rubber could tell made ahead time ...\n",
              "8                                             fry great\n",
              "9                                           great touch\n",
              "10                                    service wa prompt\n",
              "11                                        would go back\n",
              "12    cashier care ever say still ended wayyy overpr...\n",
              "13         tried cape cod ravoli chicken cranberry mmmm\n",
              "14            wa disgusted wa pretty sure wa human hair\n",
              "15                        wa shocked sign indicate cash\n",
              "16                                   highly recommended\n",
              "17                      waitress wa little slow service\n",
              "18                      place worth time let alone vega\n",
              "19                                                 like\n",
              "Name: proc_text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0-QwEVci5aw"
      },
      "source": [
        "X_bow = cv.fit_transform(X)\n",
        "\n",
        "test_bow = cv.transform(test)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBVxfmBqi5eI"
      },
      "source": [
        "# convert to array\n",
        "X_bow_arr = X_bow.toarray()\n",
        "test_bow_arr = test_bow.toarray()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMv4xtqOi5k3"
      },
      "source": [
        "# convert to DataFrame\n",
        "X_bow_df = pd.DataFrame(X_bow_arr)\n",
        "\n",
        "test_bow_df = pd.DataFrame(test_bow_arr)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv9X4UL1i5oW"
      },
      "source": [
        "# Add column names\n",
        "X_bow_df.columns = cv.get_feature_names()\n",
        "test_bow_df.columns = cv.get_feature_names()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "WcOC8MyuArT7",
        "outputId": "653e54ca-692d-4195-bccd-29e215d73828"
      },
      "source": [
        "X_bow_df.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abhor</th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>abound</th>\n",
              "      <th>absolute</th>\n",
              "      <th>absolutel</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>absolutley</th>\n",
              "      <th>abstruse</th>\n",
              "      <th>ac</th>\n",
              "      <th>accept</th>\n",
              "      <th>acceptable</th>\n",
              "      <th>access</th>\n",
              "      <th>accessable</th>\n",
              "      <th>accessing</th>\n",
              "      <th>accessory</th>\n",
              "      <th>accessoryone</th>\n",
              "      <th>accident</th>\n",
              "      <th>accidentally</th>\n",
              "      <th>accommodation</th>\n",
              "      <th>accomodate</th>\n",
              "      <th>accompanied</th>\n",
              "      <th>according</th>\n",
              "      <th>accountant</th>\n",
              "      <th>accurately</th>\n",
              "      <th>accused</th>\n",
              "      <th>ache</th>\n",
              "      <th>acknowledged</th>\n",
              "      <th>across</th>\n",
              "      <th>acted</th>\n",
              "      <th>acting</th>\n",
              "      <th>action</th>\n",
              "      <th>activate</th>\n",
              "      <th>activated</th>\n",
              "      <th>activesync</th>\n",
              "      <th>actor</th>\n",
              "      <th>actress</th>\n",
              "      <th>actual</th>\n",
              "      <th>actually</th>\n",
              "      <th>ad</th>\n",
              "      <th>...</th>\n",
              "      <th>worker</th>\n",
              "      <th>working</th>\n",
              "      <th>world</th>\n",
              "      <th>worn</th>\n",
              "      <th>worry</th>\n",
              "      <th>worse</th>\n",
              "      <th>worst</th>\n",
              "      <th>worth</th>\n",
              "      <th>worthless</th>\n",
              "      <th>worthwhile</th>\n",
              "      <th>would</th>\n",
              "      <th>wound</th>\n",
              "      <th>wow</th>\n",
              "      <th>wrap</th>\n",
              "      <th>wrapped</th>\n",
              "      <th>writer</th>\n",
              "      <th>writing</th>\n",
              "      <th>written</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wrongly</th>\n",
              "      <th>ya</th>\n",
              "      <th>yama</th>\n",
              "      <th>yawn</th>\n",
              "      <th>yay</th>\n",
              "      <th>yeah</th>\n",
              "      <th>year</th>\n",
              "      <th>yell</th>\n",
              "      <th>yellow</th>\n",
              "      <th>yellowtail</th>\n",
              "      <th>yelpers</th>\n",
              "      <th>yes</th>\n",
              "      <th>yet</th>\n",
              "      <th>young</th>\n",
              "      <th>youthful</th>\n",
              "      <th>yucky</th>\n",
              "      <th>yukon</th>\n",
              "      <th>yum</th>\n",
              "      <th>yummy</th>\n",
              "      <th>zero</th>\n",
              "      <th>zombiez</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3494 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   abhor  ability  able  abound  absolute  ...  yukon  yum  yummy  zero  zombiez\n",
              "0      0        0     0       0         0  ...      0    0      0     0        0\n",
              "1      0        0     0       0         0  ...      0    0      0     0        0\n",
              "2      0        0     0       0         0  ...      0    0      0     0        0\n",
              "3      0        0     0       0         0  ...      0    0      0     0        0\n",
              "4      0        0     0       0         0  ...      0    0      0     0        0\n",
              "\n",
              "[5 rows x 3494 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbC8sUsygXf8",
        "outputId": "66cccf65-6038-4306-d964-27dfef4a9a60"
      },
      "source": [
        "X_bow_df.isna().sum().sum()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ3uT0nCSgIX"
      },
      "source": [
        "## Train Test Split for Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULpkOc8mSIcP",
        "outputId": "45d02377-6ebd-4870-ec7f-603903c135c7"
      },
      "source": [
        "# split the training set for training and validation\n",
        "X = X_bow_df\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, \n",
        "                                                    random_state=666)\n",
        "\n",
        "print('Training Data :', X_train.shape)\n",
        "print('Testing Data : ', X_test.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data : (1786, 3494)\n",
            "Testing Data :  (596, 3494)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "BWg89TLwSIgO",
        "outputId": "83d043cc-3eab-45f7-eea3-14569a4dc731"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abhor</th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>abound</th>\n",
              "      <th>absolute</th>\n",
              "      <th>absolutel</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>absolutley</th>\n",
              "      <th>abstruse</th>\n",
              "      <th>ac</th>\n",
              "      <th>accept</th>\n",
              "      <th>acceptable</th>\n",
              "      <th>access</th>\n",
              "      <th>accessable</th>\n",
              "      <th>accessing</th>\n",
              "      <th>accessory</th>\n",
              "      <th>accessoryone</th>\n",
              "      <th>accident</th>\n",
              "      <th>accidentally</th>\n",
              "      <th>accommodation</th>\n",
              "      <th>accomodate</th>\n",
              "      <th>accompanied</th>\n",
              "      <th>according</th>\n",
              "      <th>accountant</th>\n",
              "      <th>accurately</th>\n",
              "      <th>accused</th>\n",
              "      <th>ache</th>\n",
              "      <th>acknowledged</th>\n",
              "      <th>across</th>\n",
              "      <th>acted</th>\n",
              "      <th>acting</th>\n",
              "      <th>action</th>\n",
              "      <th>activate</th>\n",
              "      <th>activated</th>\n",
              "      <th>activesync</th>\n",
              "      <th>actor</th>\n",
              "      <th>actress</th>\n",
              "      <th>actual</th>\n",
              "      <th>actually</th>\n",
              "      <th>ad</th>\n",
              "      <th>...</th>\n",
              "      <th>worker</th>\n",
              "      <th>working</th>\n",
              "      <th>world</th>\n",
              "      <th>worn</th>\n",
              "      <th>worry</th>\n",
              "      <th>worse</th>\n",
              "      <th>worst</th>\n",
              "      <th>worth</th>\n",
              "      <th>worthless</th>\n",
              "      <th>worthwhile</th>\n",
              "      <th>would</th>\n",
              "      <th>wound</th>\n",
              "      <th>wow</th>\n",
              "      <th>wrap</th>\n",
              "      <th>wrapped</th>\n",
              "      <th>writer</th>\n",
              "      <th>writing</th>\n",
              "      <th>written</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wrongly</th>\n",
              "      <th>ya</th>\n",
              "      <th>yama</th>\n",
              "      <th>yawn</th>\n",
              "      <th>yay</th>\n",
              "      <th>yeah</th>\n",
              "      <th>year</th>\n",
              "      <th>yell</th>\n",
              "      <th>yellow</th>\n",
              "      <th>yellowtail</th>\n",
              "      <th>yelpers</th>\n",
              "      <th>yes</th>\n",
              "      <th>yet</th>\n",
              "      <th>young</th>\n",
              "      <th>youthful</th>\n",
              "      <th>yucky</th>\n",
              "      <th>yukon</th>\n",
              "      <th>yum</th>\n",
              "      <th>yummy</th>\n",
              "      <th>zero</th>\n",
              "      <th>zombiez</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1672</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>980</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1846</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3494 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      abhor  ability  able  abound  absolute  ...  yukon  yum  yummy  zero  zombiez\n",
              "971       0        0     0       0         0  ...      0    0      0     0        0\n",
              "1672      0        0     0       0         0  ...      0    0      0     0        0\n",
              "520       0        0     0       0         0  ...      0    0      0     0        0\n",
              "980       0        0     0       0         0  ...      0    0      0     0        0\n",
              "1846      0        0     0       0         0  ...      0    0      0     0        0\n",
              "\n",
              "[5 rows x 3494 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lknzAnzDfe5X"
      },
      "source": [
        "## Logitics Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROS-O5NVSIjq",
        "outputId": "0f24f01b-18ab-426d-d93e-003e8c58b44e"
      },
      "source": [
        "# Logistics regression as baseline model with class weights as balanced\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(class_weight=\"balanced\",random_state=666)\n",
        "lr.fit(X_train, y_train)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=666, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3dfCxb-SInE"
      },
      "source": [
        "# Create a prediction set:\n",
        "predictions = lr.predict(X_test)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxzw8nOVSIqV",
        "outputId": "3fb8c236-7f2c-4a04-97e6-660d076a641c"
      },
      "source": [
        "# classification report\n",
        "print(metrics.classification_report(y_test,predictions))\n",
        "# Accuracy is 77%"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       310\n",
            "           1       0.79      0.72      0.75       286\n",
            "\n",
            "    accuracy                           0.77       596\n",
            "   macro avg       0.77      0.77      0.77       596\n",
            "weighted avg       0.77      0.77      0.77       596\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_pHzhUffx5E",
        "outputId": "0153d558-6ba1-4d88-eae9-5b316785a900"
      },
      "source": [
        "from sklearn import metrics\n",
        "# Check AUC\n",
        "print(metrics.roc_auc_score(y_test,lr.predict_proba(X_test)[:, 1]))\n",
        "\n",
        "# AUC 0.8425 is big improvement over the baseline model. "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8424881570042859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZe1I7TzfyFk",
        "outputId": "a36f1972-babe-4067-8f0b-bf076e90a0d3"
      },
      "source": [
        "# Check F1 Score\n",
        "print(metrics.f1_score(y_test,predictions))\n",
        "\n",
        "# F1 0.7541 is big improvement over the baseline model. "
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7540983606557377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "J0HJxrD3fyP2",
        "outputId": "e0d780d9-3cf2-4994-df03-6a5c8dcccf01"
      },
      "source": [
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "cm = ConfusionMatrix(lr, classes=[0,1])\n",
        "cm.fit(X_train, y_train)\n",
        "cm.score(X_test, y_test)\n",
        "cm.poof();"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzNpNc4JNw77"
      },
      "source": [
        "## Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0A-2Di3fyhd",
        "outputId": "3c1ee549-9f73-4dcf-cc61-00e264fff66e"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "lr = LogisticRegression(class_weight=\"balanced\",random_state=666)\n",
        "\n",
        "scores = cross_validate(lr, X_train, y_train, cv=5, scoring=['f1','f1_weighted',\n",
        "                                                             'roc_auc','accuracy'])\n",
        "\n",
        "sorted(scores.keys())\n",
        "\n",
        "#print the mean for 5 fold cross validation\n",
        "print(\"the f1 mean for 5 fold cross validation is {}\".format(\n",
        "    scores[\"test_f1\"].mean()))\n",
        "print(\"the f1_weighted mean for 5 fold cross validation is {}\".format(\n",
        "    scores[\"test_f1_weighted\"].mean()))\n",
        "print(\"the ROC AUC mean for 5 fold cross validation is {}\".format(\n",
        "    scores[\"test_roc_auc\"].mean()))\n",
        "print(\"the Accuracy mean for 5 fold cross validation is {}\".format(\n",
        "    scores[\"test_accuracy\"].mean()))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the f1 mean for 5 fold cross validation is 0.7890302338882266\n",
            "the f1_weighted mean for 5 fold cross validation is 0.7979971665712041\n",
            "the ROC AUC mean for 5 fold cross validation is 0.8671912030353119\n",
            "the Accuracy mean for 5 fold cross validation is 0.7984273038824468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flUnQGDTN8Cy"
      },
      "source": [
        "## Hyper parameter Tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4sVecaXX6Ks"
      },
      "source": [
        "# Grid Search hyper-parameter tuning\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "lr = LogisticRegression(random_state=666)\n",
        "\n",
        "\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l2']\n",
        "class_weight = ['balanced',None] \n",
        "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "max_iter = [1000,500]\n",
        "\n",
        "grid = dict(solver=solvers,penalty=penalty,C=c_values,max_iter=max_iter,\n",
        "            class_weight=class_weight)\n",
        "\n",
        "# param_grid = dict(penalty=penalty,\n",
        "#                   c=C,\n",
        "#                   class_weight=class_weight,\n",
        "#                   solver=solver,\n",
        "#                   max_iter = max_iter)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLpnSg6uYLYM",
        "outputId": "94d51540-15a9-42ac-ae75-4795696d1b1f"
      },
      "source": [
        "search = GridSearchCV(lr, param_grid=grid, n_jobs=-1, cv=5, scoring='f1_weighted',\n",
        "                      error_score=0, verbose=1)\n",
        "search = search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   36.4s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMYTc14uZAU_"
      },
      "source": [
        "print('Best Score: ', search.best_score_)\n",
        "print('Best Params: ', search.best_params_)\n",
        "\n",
        "# the F1 score increased from 0.7977 to 0.7986"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bucqS4OOk9n",
        "outputId": "f354d6e4-098c-4ad5-aac4-d093a98dbabb"
      },
      "source": [
        "search = GridSearchCV(lr, param_grid=grid, n_jobs=-1, cv=5, scoring='accuracy',\n",
        "                      error_score=0, verbose=1)\n",
        "search = search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   35.4s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewX4DQm4OlRl"
      },
      "source": [
        "print('Best Score: ', search.best_score_)\n",
        "print('Best Params: ', search.best_params_)\n",
        "\n",
        "# the accuracy and F1 score hyperparameter tunning best score configurations are the same.\n",
        "# the accuracy increased from 0.7985 to 0.7990"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS49UoJZrxfu"
      },
      "source": [
        "## Re-Train the model on whole dataset with Tuned Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdgZvl_oZArA"
      },
      "source": [
        "lr = LogisticRegression(random_state=666,C = 1.0, class_weight= 'balanced', \n",
        "                        max_iter = 1000, penalty= 'l2', solver= 'liblinear')\n",
        "\n",
        "lr = lr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vCXftB2soHb"
      },
      "source": [
        "# Create a prediction set:\n",
        "predictions = lr.predict(test_bow_df)\n",
        "prob = lr.predict_proba(test_bow_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwrHehcMs9w7"
      },
      "source": [
        "y_df_test = df_test.Polarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGzcS1T-Vd2_"
      },
      "source": [
        "print(lr.coef_, lr.intercept_)\n",
        "coef = pd.DataFrame(lr.coef_,columns=X_train.columns)\n",
        "\n",
        "coef = pd.concat([pd.DataFrame(lr.intercept_),coef],axis=1)\n",
        "coef.head()\n",
        "\n",
        "#0 is the intercept"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHrdNytFd1M0"
      },
      "source": [
        "### Part 1.c. Assessing\n",
        "\n",
        "Use the testing data to measure the accuracy and F1-score of your model.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiS4GXCSs94m"
      },
      "source": [
        "# classification report\n",
        "print(metrics.classification_report(y_df_test,predictions))\n",
        "\n",
        "# Accuracy is 75% which is lower than hyper parameter tunning. F1 score is 0.7353 \n",
        "# is lower than hyperparameter tunning model. There is a possibility of over \n",
        "# fitting or sometype of drift."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dagJC29stOEK"
      },
      "source": [
        "from sklearn import metrics\n",
        "# Check AUC\n",
        "print(metrics.roc_auc_score(y_df_test,lr.predict_proba(test_bow_df)[:, 1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-n37Kzfs-AP"
      },
      "source": [
        "# Check F1 Score\n",
        "print(metrics.f1_score(y_df_test,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFQgYh9rtgg4"
      },
      "source": [
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "cm = ConfusionMatrix(lr, classes=[0,1])\n",
        "cm.fit(X_train, y_train)\n",
        "cm.score(test_bow_df, y_df_test)\n",
        "cm.poof();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40hmco7wd1M1"
      },
      "source": [
        "### Part 2. Given the accuracy and F1-score of your model, are you satisfied with the results, from a business point of view? Explain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yaa02kpMijO6"
      },
      "source": [
        "# NLTK Sentiment Analyser\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sent = SentimentIntensityAnalyzer()\n",
        "\n",
        "def check_sentiment(x):\n",
        "    if sent.polarity_scores(x)['compound']>0:\n",
        "      result = 1\n",
        "    else:\n",
        "      result=0\n",
        "    return result\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TEhhoWhtG5N"
      },
      "source": [
        "# Textblob Sentiment Analyser\n",
        "from textblob import TextBlob\n",
        "import textwrap\n",
        "\n",
        "def check_sentiment_tb(x):\n",
        "    if TextBlob(x).polarity > 0:\n",
        "      result = 1\n",
        "    else:\n",
        "      result=0\n",
        "    return result\n",
        "\n",
        "np.set_printoptions(linewidth=160)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI04Lr5a9-O_"
      },
      "source": [
        "# Check pre-trained models on training data and measure metric performance\n",
        "df_train[\"NLTK_Pol\"]=df_train[\"Sentence\"].apply(lambda x: check_sentiment(x))\n",
        "df_train[\"TB_Pol\"]=df_train[\"Sentence\"].apply(lambda x: check_sentiment_tb(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjvytSVB9-Tu"
      },
      "source": [
        " # classification report\n",
        "print(metrics.classification_report(df_train[\"Polarity\"],df_train[\"NLTK_Pol\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yglZlsW_9-Xj"
      },
      "source": [
        "# classification report\n",
        "print(metrics.classification_report(df_train[\"Polarity\"],df_train[\"TB_Pol\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vu_JuOiU9-mL"
      },
      "source": [
        "# Check F1 Score\n",
        "print(metrics.f1_score(df_train[\"Polarity\"],df_train[\"NLTK_Pol\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYqKFErl-D4Z"
      },
      "source": [
        "# Check F1 Score \n",
        "print(metrics.f1_score(df_train[\"Polarity\"],df_train[\"TB_Pol\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNWYARF88Vre"
      },
      "source": [
        "# Check pre-trained models on test data and measure metric performance\n",
        "# Entire text \n",
        "df_test[\"NLTK_Pol\"]=df_test[\"Sentence\"].apply(lambda x: check_sentiment(x))\n",
        "df_test[\"TB_Pol\"]=df_test[\"Sentence\"].apply(lambda x: check_sentiment_tb(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVLPFoZZA7aT"
      },
      "source": [
        "# classification report\n",
        "print(metrics.confusion_matrix(y_df_test,df_test[\"NLTK_Pol\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlABCoD0A7QS"
      },
      "source": [
        "# classification report\n",
        "print(metrics.confusion_matrix(y_df_test,df_test[\"TB_Pol\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ0olwxa8ZQs"
      },
      "source": [
        "# classification report\n",
        "print(metrics.classification_report(y_df_test,df_test[\"NLTK_Pol\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKCRwjyU8ZVx"
      },
      "source": [
        "# classification report\n",
        "print(metrics.classification_report(y_df_test,df_test[\"TB_Pol\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S0s5iog8ZZg"
      },
      "source": [
        "# Check F1 Score\n",
        "print(metrics.f1_score(y_df_test,df_test[\"NLTK_Pol\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f21iBw38ZdI"
      },
      "source": [
        "# Check F1 Score \n",
        "print(metrics.f1_score(y_df_test,df_test[\"TB_Pol\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jIbgveM0LzK"
      },
      "source": [
        "# Check pre-trained models on test data and measure metric performance\n",
        "# Entire tex\n",
        "df_test[\"NLTK_Pol\"]=df_test[\"proc_text\"].apply(lambda x: check_sentiment(x))\n",
        "df_test[\"TB_Pol\"]=df_test[\"proc_text\"].apply(lambda x: check_sentiment_tb(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJh70fVeBHsv"
      },
      "source": [
        "# classification report\n",
        "print(metrics.confusion_matrix(y_df_test,df_test[\"NLTK_Pol\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RrfjUM2BIG7"
      },
      "source": [
        "# classification report\n",
        "print(metrics.confusion_matrix(y_df_test,df_test[\"TB_Pol\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSN39SEv1xEZ"
      },
      "source": [
        "# classification report\n",
        "print(metrics.classification_report(y_df_test,df_test[\"NLTK_Pol\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOHtfQOE1xlA"
      },
      "source": [
        "# classification report\n",
        "print(metrics.classification_report(y_df_test,df_test[\"TB_Pol\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PemZ9Kb62TqH"
      },
      "source": [
        "# Check F1 Score\n",
        "print(metrics.f1_score(y_df_test,df_test[\"NLTK_Pol\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aJDcpCH2Us-"
      },
      "source": [
        "# Check F1 Score \n",
        "print(metrics.f1_score(y_df_test,df_test[\"TB_Pol\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izVASTQ6d1M1"
      },
      "source": [
        "The best way to evaluate a model is to define a customised payoff/ cost matrix and helps to understand how to value false positive and false negatives. In the absense of cost payoff matrix I will assume the cost of False negatives are very high as we are trying to convert the detractors to promoters which require time, resource and moentary investment.\n",
        "\n",
        "- The accuracy of Logistic Regression model (df_test) is 0.75\n",
        "- The AUC of Logistic Regression model (df_test) is 0.844\n",
        "- The f1 score of Logistic Regression model (df_test) is 0.735\n",
        "\n",
        "\n",
        "- The accuracy of NLTK Sentiment Analysis model (df_test) is 0.78 increases to 0.80 with entire text versus processed text (very close to training set metrics)\n",
        "- The f1 score of NLTK Sentiment Analysis model (df_test) is 0.786 increases to 0.806 with entire text versus processed text (very close to training set metrics)\n",
        "\n",
        "\n",
        "- The accuracy of Textblob Sentiment Analysis model (df_test) is 0.75 increases to 0.76 with entire text versus processed text. (close to training set metrics)\n",
        "- The f1 score of Textblob Sentiment Analysis model (df_test) is 0.757 increases to 0.770 with entire text versus processed text.(close to training set metrics)\n",
        "\n",
        "Ideally unless I believe that my input data is significantly different from training data or pre-trained model training data i.e. specific to my industry or organisation I would rather use pre-trained models. The accuracy and f1 scores are slightly better and I can work off the shelf to deploy the solution faster wihtout really increaase to the compute or storage needs. The pre-trained model does reduce the False Negatives from 106 (LR model) to 68 with NLTK and 75 with TextBlob.\n",
        "\n",
        "\n",
        "Lets assume that we can not use the pre-trained models for building this analysis. I think my model has good accuracy (75%), great AUC score of 0.844, great precision for class positive (1) of 0.83 though we can improve the recall by balancing the trade off between recall and precision by adjusting the thresholds. As the custom metric is heavily focused on precision for class 0 before deployment I would like to optimize the model based on the custom metric.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HVFjHlfd1M1"
      },
      "source": [
        "### Part 3. Show five example instances in which your model’s predictions were incorrect. Describe why you think the model was wrong. Don’t just guess: dig deep to figure out the root cause."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IAUXUQt1AAH"
      },
      "source": [
        "def check_sentiment(x):\n",
        "    return sent.polarity_scores(x)['compound']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN737Ypg1Av8"
      },
      "source": [
        "def check_sentiment_tb(x):\n",
        "    return TextBlob(x).polarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad7SWEHwd1M2"
      },
      "source": [
        "# Concaternate the test dataset with predictions and probabilities\n",
        "data = pd.concat([df_test,pd.DataFrame(predictions),pd.DataFrame(prob)],axis=1)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkISHSiH6aUY"
      },
      "source": [
        "# rename the columns\n",
        "data.columns = ['Sentence','Polarity','Senten_count','length','word_count','UNQ_word_count','proc_text',\"NLTK_Pol\",\"TB_Pol\",\"Prediction\",\"Prob_Class_0\",\"Prob_Class_1\"]\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEIXERhtCexw"
      },
      "source": [
        "# build a dataset for misclassified instances\n",
        "data_analyse = data[((data[\"Polarity\"]==1) & (data[\"Prediction\"]==0)) | \n",
        "                    ((data[\"Polarity\"]==0) & (data[\"Prediction\"]==1)) ]\n",
        "\n",
        "data_analyse.reset_index(drop=True,inplace=True)\n",
        "data_analyse.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DRzVT48wfgh"
      },
      "source": [
        "# Analyse Wrong classification Use case 1\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[8,\"Sentence\"]),\n",
        "      check_sentiment(data_analyse.loc[8,\"Sentence\"]))\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[8,\"proc_text\"]),\n",
        "      check_sentiment(data_analyse.loc[8,\"proc_text\"]))\n",
        "\n",
        "print(data_analyse.loc[8,:],data_analyse.loc[8,\"Sentence\"])\n",
        "# Sentence Analysis\n",
        "# NLTK Sentiment analysis predicts positive \n",
        "# Textblob Sentiment analysis predicts neutral \n",
        "\n",
        "# Processed Text Analysis\n",
        "# NLTK Sentiment analysis predicts positive \n",
        "# Textblob Sentiment analysis predicts positive \n",
        "\n",
        "# Actual Polarity negative\n",
        "# Logistic Regression prediction positive\n",
        "# \n",
        "print(lr.intercept_,coef.loc[:,\"even\"],coef.loc[:,\"good\"],coef.loc[:,\"value\"])\n",
        "\n",
        "# Reason: Stopwords removed not which changes the tone of the text.\n",
        "# camp: not in BoW"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyA8_hD2hCvu"
      },
      "source": [
        "# Analyse Wrong classification Use case 2\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[5,\"Sentence\"]),\n",
        "      check_sentiment(data_analyse.loc[5,\"Sentence\"]))\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[5,\"proc_text\"]),\n",
        "      check_sentiment(data_analyse.loc[5,\"proc_text\"]))\n",
        "\n",
        "print(data_analyse.loc[5,:],data_analyse.loc[5,\"Sentence\"])\n",
        "\n",
        "print(data_analyse.loc[5,\"proc_text\"])\n",
        "\n",
        "# Sentence Analysis\n",
        "# NLTK Sentiment analysis predicts positive \n",
        "# Textblob Sentiment analysis predicts positive \n",
        "\n",
        "# Processed Text Analysis\n",
        "# NLTK Sentiment analysis predicts positive \n",
        "# Textblob Sentiment analysis predicts positive \n",
        "\n",
        "# Actual Polarity positive\n",
        "# Logistic Regression prediction negative\n",
        "print(lr.intercept_,coef.loc[:,\"like\"],coef.loc[:,\"cable\"],coef.loc[:,\"company\"],\n",
        "      coef.loc[:,\"summary\"],coef.loc[:,\"sounded\"],coef.loc[:,\"interesting\"],\n",
        "      coef.loc[:,\"watched\"],coef.loc[:,\"twice\"],coef.loc[:,\"already\"],\n",
        "      coef.loc[:,\"probably\"])\n",
        "\n",
        "already_df = df_train.loc[df_train['Sentence'].str.contains(\"already\", case=False)]\n",
        "print(already_df.shape)\n",
        "already_df.Polarity.value_counts().plot.bar()\n",
        "\n",
        "# Reason: already has a very high negative coefficient. In the training dataset, \n",
        "# already was a feature only in 1 instance with polarity 0 thus coefficient was \n",
        "# negative A pre-trained model like NLTK, Textblob predicts the sentiment correctly\n",
        "# armand, assante: not in BoW"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jLkSdpntfvW"
      },
      "source": [
        "# Analyse Wrong classification Use case 3\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[2,\"Sentence\"]),\n",
        "      check_sentiment(data_analyse.loc[2,\"Sentence\"]))\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[2,\"proc_text\"]),\n",
        "      check_sentiment(data_analyse.loc[2,\"proc_text\"]))\n",
        "\n",
        "\n",
        "print(data_analyse.loc[2,:],data_analyse.loc[2,\"Sentence\"])\n",
        "\n",
        "print(data_analyse.loc[2,\"proc_text\"])\n",
        "\n",
        "# Sentence Analysis\n",
        "# NLTK Sentiment analysis predicts positive \n",
        "# Textblob Sentiment analysis predicts negative \n",
        "\n",
        "# Processed Text Analysis\n",
        "# NLTK Sentiment analysis predicts negative\n",
        "# Textblob Sentiment analysis predicts negative \n",
        "\n",
        "# Actual Polarity positive\n",
        "# Logistic Regression prediction negative\n",
        "print(lr.intercept_,coef.loc[:,\"soundtrack\"],coef.loc[:,\"terrible\"],coef.loc[:,\"either\"]) \n",
        "\n",
        "inp_df = df_train.loc[df_train['Sentence'].str.contains(\"soundtrack\", case=False)]\n",
        "print(inp_df.shape)\n",
        "# inp_df.Polarity.value_counts().plot.bar()\n",
        "# soundtrack has 2 instances: 1 with Polarity 1 and 1 with Polarity 0\n",
        "\n",
        "inp_df = df_train.loc[df_train['Sentence'].str.contains(\"terrible\", case=False)]\n",
        "print(inp_df.shape)\n",
        "inp_df.Polarity.value_counts().plot.bar()\n",
        "# terrible has 24 instances all with Polarity 0 \n",
        "\n",
        "# Reason: both soundtrack and terrible have negative coefficients. As keyword \n",
        "# wasnt was taken out due to stop word removal the pre-trained models are not \n",
        "# classifying the text correctly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcSoe2lh-PyK"
      },
      "source": [
        "# Analyse Wrong classification Use case 4\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[12,\"Sentence\"]),\n",
        "      check_sentiment(data_analyse.loc[12,\"Sentence\"]))\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[12,\"proc_text\"]),\n",
        "      check_sentiment(data_analyse.loc[12,\"proc_text\"]))\n",
        "\n",
        "print(data_analyse.loc[12,:],data_analyse.loc[12,[\"Sentence\"]])\n",
        "\n",
        "print(data_analyse.loc[12,\"proc_text\"])\n",
        "\n",
        "# Sentence Analysis\n",
        "# NLTK Sentiment analysis predicts positive \n",
        "# Textblob Sentiment analysis predicts positive \n",
        "\n",
        "# Processed Text Analysis\n",
        "# NLTK Sentiment analysis predicts positive \n",
        "# Textblob Sentiment analysis predicts positive \n",
        "\n",
        "# Actual Polarity negative\n",
        "# Logistic Regression prediction positive\n",
        "print(lr.intercept_,coef.loc[:,\"finally\"],coef.loc[:,\"get\"],coef.loc[:,\"ending\"],\n",
        "      coef.loc[:,\"would\"],coef.loc[:,\"great\"],coef.loc[:,\"handled\"],\n",
        "      coef.loc[:,\"handle\"],coef.loc[:,\"people\"])\n",
        "\n",
        "inp_df = df_train.loc[df_train['Sentence'].str.contains(\"would\", case=False)]\n",
        "print(inp_df.shape)\n",
        "inp_df.Polarity.value_counts().plot.bar()\n",
        "# would has 80 instances 52 with Polarity 0 and 28 with polarity 1\n",
        "\n",
        "# Reason: Would and get have high positive coefficients ideally I would expect \n",
        "# would post lemmatizer and stop word would be removed. A pre-trained model \n",
        "# like NLTK, Textblob predicts the sentiment correctly\n",
        "# jerry, falwell: not in BoW\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2E68wzS-QRi"
      },
      "source": [
        "# Analyse Wrong classification Use case 5\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[30,\"Sentence\"]),\n",
        "      check_sentiment(data_analyse.loc[30,\"Sentence\"]))\n",
        "\n",
        "print(check_sentiment_tb(data_analyse.loc[30,\"proc_text\"]),\n",
        "      check_sentiment(data_analyse.loc[30,\"proc_text\"]))\n",
        "\n",
        "print(data_analyse.loc[30,:],data_analyse.loc[30,[\"Sentence\"]])\n",
        "\n",
        "print(data_analyse.loc[30,\"proc_text\"])\n",
        "\n",
        "# Sentence Analysis\n",
        "# NLTK Sentiment analysis predicts negative \n",
        "# Textblob Sentiment analysis predicts neutral \n",
        "\n",
        "# Processed Text Analysis\n",
        "# NLTK Sentiment analysis predicts positive \n",
        "# Textblob Sentiment analysis predicts neutral \n",
        "\n",
        "# Actual Polarity negative\n",
        "# Logistic Regression prediction positive\n",
        "print(lr.intercept_,coef.loc[:,\"recommended\"])\n",
        "\n",
        "rec_df = df_train.loc[df_train['Sentence'].str.contains(\"recommended\", case=False)]\n",
        "print(rec_df.shape)\n",
        "rec_df.Polarity.value_counts().plot.bar()\n",
        "\n",
        "# Reason: Not removed during stopword removal process which changes the meaning \n",
        "# of the sentence from not recommended to recommended. The pre-trained model may \n",
        "# be able to correctly predict the tone for the sentence but not for processed \n",
        "# text as the keyword is removed.\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}